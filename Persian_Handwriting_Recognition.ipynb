{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Persian_Handwriting_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KjmPPZWSw94B",
        "ObDIJa5519fS",
        "zvxoQ6nasG0G",
        "ljeVdLAftWMJ",
        "mMOBptv4tzUV",
        "cnqGNZYht-7h",
        "NTyrrZ1WC-pZ",
        "vLuCTTmYwnjp",
        "rAxAsyWDEtsj",
        "-sxai6O-MRKT",
        "V6XBvgnOlK7K"
      ],
      "toc_visible": true,
      "mount_file_id": "1wpCgG1zcmi41j-_Rn0zGPL1keo2dXAHX",
      "authorship_tag": "ABX9TyOQ+sIzAv6U77H9YSAR2/mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farnazkash/Persian_Handwriting_Recognition/blob/master/Persian_Handwriting_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPjSTw8Cr8wH",
        "colab_type": "text"
      },
      "source": [
        "***Persian_Handwriting_Recognition***\n",
        "==\n",
        "\n",
        "*   Input : A form containing ID, Firstname, Lastname and Degree of the form filler.\n",
        "\n",
        "*   Output: these four fields of the form\n",
        "\n",
        "In this project, a dataset of handwritten characters and digits has been gathered. Then two neural networks have been trained to classify handwritten Persian letters and digits. So finally it can automatically read the form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjmPPZWSw94B",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFA8UnIqxHfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2 as cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2 as cv2\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObDIJa5519fS",
        "colab_type": "text"
      },
      "source": [
        "#Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zthRd2FL16Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ID = {}\n",
        "Firstname = {}\n",
        "Lastname = {}\n",
        "Degree = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANPfKL11sF3H",
        "colab_type": "text"
      },
      "source": [
        "#DATASET\n",
        "\n",
        "In the first step, we need to prepare the dataset. In this project, around 300 images including handwritten Persian letters and digits have been used. To make the labeling process easier, the names of folders have chosen as the labels of the data in this dataset.\n",
        "So, the dataset has separated to two digits and letters folders.\n",
        "Digits folder has ten folders ranging from zero to nine.\n",
        "Because Persian has 32 letters, in letters folder we have 32 folders ranging from 0 (letter 'الف') to 31 (letter 'ی')."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvxoQ6nasG0G",
        "colab_type": "text"
      },
      "source": [
        "## Create Dataset Folders\n",
        "To use these images, their perspective should be corrected.\n",
        "Each image that has been used in the dataset has 4 [aruco](https://docs.opencv.org/trunk/d5/dae/tutorial_aruco_detection.html) markers in its corners. These markers have helped us to rectify images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkil22mc_IPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "codes = ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
        "         '2', '3',\n",
        "         '4', '5', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '6',\n",
        "         '7', '8', '9'\n",
        "         ]\n",
        "folder_counter = np.zeros(42)\n",
        "\n",
        "def extract_cells(f,file):\n",
        "    I = f\n",
        "    dictionary = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_250)\n",
        "    parameters = cv2.aruco.DetectorParameters_create()\n",
        "    markerCorners, markerIds, rejectedCandidates = cv2.aruco.detectMarkers(I, dictionary, parameters=parameters)\n",
        "    \n",
        "    aruco_list = {}\n",
        "    for k in range(len(markerCorners)):\n",
        "        temp_1 = markerCorners[k]\n",
        "        temp_1 = temp_1[0]\n",
        "        temp_2 = markerIds[k]\n",
        "        temp_2 = temp_2[0]\n",
        "        aruco_list[temp_2] = temp_1\n",
        "\n",
        "    p1 = aruco_list[30][0]\n",
        "    p2 = aruco_list[31][1]\n",
        "    p3 = aruco_list[32][3]\n",
        "    p4 = aruco_list[33][2]\n",
        "    points2 = np.array([(0, 0),\n",
        "                        (392, 0),\n",
        "                        (0, 588),\n",
        "                        (392, 588)]).astype(np.float32)\n",
        "\n",
        "    points1 = np.array([p1, p2, p3, p4], dtype=np.float32)\n",
        "\n",
        "    m = 588\n",
        "    n = 392\n",
        "    output_size = (n, m)\n",
        "    H = cv2.getPerspectiveTransform(points1, points2)\n",
        "    J = cv2.warpPerspective(I, H, output_size)\n",
        "\n",
        "    col_number = n // 28\n",
        "    row_number = m // 28\n",
        "\n",
        "    form_num = file[8]\n",
        "    for i in range(row_number):\n",
        "        for j in range(col_number):\n",
        "            ROI = J[i * 28:(i * 28) + 28, j * 28:(j * 28) + 28]\n",
        "            index = i if form_num == '1' else i + 21\n",
        "            if not os.path.exists('dataset/'+codes[index]):\n",
        "                os.makedirs('dataset/'+ codes[index])\n",
        "            if not (i < 2 and (j < 2 or j > 11)) and not (i > 18 and (j < 2 or j > 11)):\n",
        "                cv2.imwrite('dataset/{}/{}.png'.format(codes[index], str(folder_counter[int(codes[index])])), ROI)\n",
        "                folder_counter[int(codes[index])] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAB23l0r_3iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = './dataset/'\n",
        "images_list = os.listdir(raw_data)\n",
        "\n",
        "for file in images_list:\n",
        "    f = cv2.imread(raw_data + file)\n",
        "    extract_cells(f,file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljeVdLAftWMJ",
        "colab_type": "text"
      },
      "source": [
        "##Labeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMOBptv4tzUV",
        "colab_type": "text"
      },
      "source": [
        "###Digit Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rQmShApA6PJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dirs_digits = glob.glob(\"dataset/digits/*\")\n",
        "train_dirs_digits.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "data_digit = []\n",
        "labels_digit = []\n",
        "for train_dir in tqdm(train_dirs_digits):\n",
        "  imgPaths = glob.glob(train_dir + \"/*.png\")\n",
        "  imgPaths.sort()\n",
        "  for imgPath in tqdm(imgPaths):\n",
        "    image = load_img(imgPath, target_size=(28, 28), grayscale=True)\n",
        "    image = img_to_array(image)\n",
        "    data_digit.append(image)\n",
        "    label = imgPath.split(os.path.sep)[-2]\n",
        "    label = int(label)\n",
        "    labels_digit.append(label)\n",
        "\n",
        "with open('data_digit.pkl', 'wb') as f:\n",
        "  pickle.dump(data_digit, f)\n",
        "\n",
        "with open('labels_digit.pkl', 'wb') as fi:\n",
        "  pickle.dump(labels_digit, fi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnqGNZYht-7h",
        "colab_type": "text"
      },
      "source": [
        "###Letter Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCBU7y8VBNKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dirs = glob.glob(\"dataset/letter/*\")\n",
        "train_dirs.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "data_letter = []\n",
        "labels_letter = []\n",
        "for train_dir in tqdm(train_dirs):\n",
        "    imgPaths = glob.glob(train_dir + \"/*.png\")\n",
        "    imgPaths.sort()\n",
        "    for imgPath in tqdm(imgPaths):\n",
        "        image = load_img(imgPath, target_size=(28, 28), grayscale=True)\n",
        "        image = img_to_array(image)\n",
        "        data_letter.append(image)\n",
        "\n",
        "        label = imgPath.split(os.path.sep)[-2]\n",
        "        label = int(label)\n",
        "        labels_letter.append(label)\n",
        "\n",
        "with open('data_letter.pkl', 'wb') as f:\n",
        "  pickle.dump(data_letter, f)\n",
        "\n",
        "with open('labels_letter.pkl', 'wb') as fi:\n",
        "  pickle.dump(labels_letter, fi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTyrrZ1WC-pZ",
        "colab_type": "text"
      },
      "source": [
        "##Reading Data & Label Files\n",
        "Once the dataset prepared, by saving data and labels to files, you won't need to do the labeling process again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0cOxHoGDIL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_digit.pkl', 'rb') as f:\n",
        "  data_digit = pickle.load(f)\n",
        "\n",
        "with open('labels_digit.pkl', 'rb') as fi:\n",
        "  labels_digit = pickle.load(fi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM5U5UOEDNLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_letter.pkl', 'rb') as f:\n",
        "  data_letter = pickle.load(f)\n",
        "\n",
        "with open('labels_letter.pkl', 'rb') as fi:\n",
        "  labels_letter = pickle.load(fi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-IGzoEKDbZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "190bd44c-fe28-4eaf-c28f-bc4773820b1a"
      },
      "source": [
        "print(\"digits data size:\")\n",
        "print(len(data_digit),len(labels_digit))\n",
        "print(\"letters data size:\")\n",
        "print(len(data_letter),len(labels_letter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "digits data size:\n",
            "15848 15848\n",
            "letters data size:\n",
            "65884 65884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLuCTTmYwnjp",
        "colab_type": "text"
      },
      "source": [
        "# Read Forms & Extract Cells\n",
        "Reading test forms from a folder and extracting cells that have digits or letters and saving extracted cells in a folder with the name of the form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NWKs_dc1WLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def empty_cell(cell):\n",
        "    x1 = int(cell.shape[0] * 0.2)\n",
        "    x2 = int(cell.shape[0] * 0.8)\n",
        "    y1 = int(cell.shape[1] * 0.2)\n",
        "    y2 = int(cell.shape[1] * 0.8)\n",
        "    cell = cell[x1:x2, y1:y2]\n",
        "    gray = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 57, 7)\n",
        "    total_white = cv2.countNonZero(thresh)\n",
        "    ratio = total_white / float((x2-x1) * (y2-y1))\n",
        "    if ratio > 0.98:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yDrCJSZ1eKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_degree(options):\n",
        "    min_ratio = math.inf\n",
        "    min_index = 0\n",
        "\n",
        "    for index, opt in enumerate(options):\n",
        "        x1 = int(opt.shape[0] * 0.2)\n",
        "        x2 = int(opt.shape[0] * 0.8)\n",
        "        y1 = int(opt.shape[1] * 0.2)\n",
        "        y2 = int(opt.shape[1] * 0.8)\n",
        "        opt = opt[x1:x2, y1:y2]\n",
        "\n",
        "        gray = cv2.cvtColor(opt, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 57, 5)\n",
        "        total_white = cv2.countNonZero(thresh)\n",
        "\n",
        "        ratio = total_white / float(thresh.shape[0] * thresh.shape[1])\n",
        "        if (ratio < min_ratio):\n",
        "            min_ratio = ratio\n",
        "            min_index = index\n",
        "    return min_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IE_J3KAxzUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extracted_form_test(path):\n",
        "    I = cv2.imread(path)\n",
        "    dictionary = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_250)\n",
        "    parameters = cv2.aruco.DetectorParameters_create()\n",
        "    markerCorners, markerIds, rejectedCandidates = cv2.aruco.detectMarkers(I, dictionary, parameters=parameters)\n",
        "\n",
        "    aruco_list = {}\n",
        "    for k in range(len(markerCorners)):\n",
        "        temp_1 = markerCorners[k]\n",
        "        temp_1 = temp_1[0]\n",
        "        temp_2 = markerIds[k]\n",
        "        temp_2 = temp_2[0]\n",
        "        aruco_list[temp_2] = temp_1\n",
        "\n",
        "    p1 = aruco_list[34][3]\n",
        "    p2 = aruco_list[35][2]\n",
        "    p3 = aruco_list[33][0]\n",
        "    p4 = aruco_list[36][1]\n",
        "\n",
        "    width = 500\n",
        "    height = 550\n",
        "    points2 = np.array([(0, 0),\n",
        "                        (width, 0),\n",
        "                        (0, height),\n",
        "                        (width, height)]).astype(np.float32)\n",
        "\n",
        "    points1 = np.array([p1, p2, p3, p4], dtype=np.float32)\n",
        "\n",
        "    output_size = (width, height)\n",
        "    H = cv2.getPerspectiveTransform(points1, points2)\n",
        "    J = cv2.warpPerspective(I, H, output_size)\n",
        "\n",
        "    gray = cv2.cvtColor(J, cv2.COLOR_BGR2GRAY)\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 57, 7)\n",
        "    kernelOpen = np.ones((2, 2), np.uint8)\n",
        "    open = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernelOpen)\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    close = cv2.morphologyEx(open, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "\n",
        "    min_x = 5\n",
        "    max_x = 50\n",
        "    dir = path.split(os.path.sep)[-1]\n",
        "    folder_name = dir[:-4]\n",
        "    image_number = 1\n",
        "    count = 0\n",
        "    index = 0\n",
        "    degree = [\"PHD\", \"MS\", \"BS\"]\n",
        "    info = ['ID','FN', 'LN']\n",
        "    degree_option = []\n",
        "    sorted_Y = sorted(cnts, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
        "    sorted_X = sorted(cnts, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "\n",
        "    for c in sorted_Y:\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        if (x > min_x and x < max_x and y < 280 and w>10):\n",
        "            square_w = w // 9 + 5\n",
        "            h -= 5\n",
        "            for i in range(0, 8):\n",
        "                x_start = x + square_w * i\n",
        "                cell = J[y:y + h, x_start:x_start + square_w]\n",
        "                if not os.path.exists('extracted_form_test/' + str(folder_name)):\n",
        "                  os.makedirs('extracted_form_test/' + str(folder_name))\n",
        "                if not empty_cell(cell):\n",
        "                  cv2.imwrite('extracted_form_test/{}/{}.png'.format(str(folder_name) , info[index] + str(image_number)), cell)\n",
        "                  image_number += 1\n",
        "            index += 1\n",
        "            image_number = 1\n",
        "    for c in sorted_X:\n",
        "        x, y, w, h = cv2.boundingRect(c)\n",
        "        if (w > 16 and w < 22 and y > 300 and h / w > 0.95):\n",
        "            cell = J[y:y + h, x:x + w]\n",
        "            if not os.path.exists('extracted_form_test/' + str(folder_name)):\n",
        "              os.makedirs('extracted_form_test/' + str(folder_name))\n",
        "            cv2.imwrite('extracted_form_test/{}/{}.png'.format(str(folder_name), degree[count]), cell)\n",
        "            degree_option.append(cell)\n",
        "            count += 1\n",
        "\n",
        "    return degree[detect_degree(degree_option)]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5TImdWQxnzk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e99e7e0-0b70-4d6b-cf39-1a3887c36340"
      },
      "source": [
        "form_test_dir = glob.glob(\"form_test/*\")\n",
        "\n",
        "for test_dir in tqdm(form_test_dir):\n",
        "    dir = test_dir.split(os.path.sep)[-1]\n",
        "    folder_name = dir[:-4]\n",
        "    Degree[folder_name] = extracted_form_test(test_dir)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [05:27<00:00, 16.40s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAxAsyWDEtsj",
        "colab_type": "text"
      },
      "source": [
        "# Digit Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn5ulSw1E1Pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes_digit = 10\n",
        "EPOCHS_digit = 10\n",
        "BS_digit = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Qoqp42KCVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_digit = np.array(data_digit, dtype=np.float) / 255.\n",
        "labels_digit = np.array(labels_digit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oq94tSEFShj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_input_digit, test_input_digit, train_target_digit, test_target_digit =  train_test_split(data_digit,\n",
        "                                                                              labels_digit,\n",
        "                                                                              test_size=0.05,\n",
        "                                                                              random_state=123)\n",
        "train_input_digit, valid_input_digit, train_target_digit, valid_target_digit =  train_test_split(train_input_digit,\n",
        "                                                                                train_target_digit,\n",
        "                                                                                test_size=0.25,\n",
        "                                                                                random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e2F-q9FF6R9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "train_target_digit = to_categorical(train_target_digit, num_classes=num_classes_digit)\n",
        "valid_target_digit = to_categorical(valid_target_digit, num_classes=num_classes_digit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-sn7ZCJGIVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "aug = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_GjetfAGQF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "from keras.models import Model\n",
        "def build_model(inputs):\n",
        "  x = inputs\n",
        "\n",
        "  x = Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation=\"relu\")(x)\n",
        "  x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "\n",
        "  x = Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation=\"relu\")(x)\n",
        "  x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x) \n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(500, activation=\"relu\")(x)\n",
        "  outputs = Dense(num_classes_digit, activation=\"softmax\")(x)\n",
        "\n",
        "  model = Model(inputs, outputs, name=\"LeNet\")\n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S9Qr8ajGUmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "204cea6e-17c8-4538-c56c-a1e678cf5d78"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "input = Input((28, 28, 1))\n",
        "model_digit = build_model(input)\n",
        "\n",
        "opt = Adam()\n",
        "model_digit.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"acc\"])\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=\"model_digit.h5\",\n",
        "                             monitor=\"val_acc\",\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "batches = aug.flow(train_input_digit, train_target_digit, batch_size=BS_digit)\n",
        "training_log = model_digit.fit_generator(batches,\n",
        "                        samples_per_epoch=batches.n,\n",
        "                        steps_per_epoch=len(train_input_digit) // BS_digit,\n",
        "                        validation_data=[valid_input_digit, valid_target_digit],\n",
        "                        epochs=EPOCHS_digit,\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"LeNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 14, 14, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 500)               1225500   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 1,256,080\n",
            "Trainable params: 1,256,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=352, validation_data=[array([[[..., epochs=10, callbacks=[<keras.ca...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "352/352 [==============================] - 28s 80ms/step - loss: 1.7767 - acc: 0.3348 - val_loss: 0.9924 - val_acc: 0.6743\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.67428, saving model to model_digit.h5\n",
            "Epoch 2/10\n",
            "352/352 [==============================] - 28s 80ms/step - loss: 0.9304 - acc: 0.6914 - val_loss: 0.5183 - val_acc: 0.8249\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.67428 to 0.82492, saving model to model_digit.h5\n",
            "Epoch 3/10\n",
            "352/352 [==============================] - 28s 79ms/step - loss: 0.6208 - acc: 0.7890 - val_loss: 0.3372 - val_acc: 0.8921\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.82492 to 0.89214, saving model to model_digit.h5\n",
            "Epoch 4/10\n",
            "352/352 [==============================] - 28s 79ms/step - loss: 0.4768 - acc: 0.8430 - val_loss: 0.2818 - val_acc: 0.9033\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.89214 to 0.90329, saving model to model_digit.h5\n",
            "Epoch 5/10\n",
            "352/352 [==============================] - 28s 79ms/step - loss: 0.3657 - acc: 0.8789 - val_loss: 0.2331 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.90329 to 0.92003, saving model to model_digit.h5\n",
            "Epoch 6/10\n",
            "352/352 [==============================] - 28s 79ms/step - loss: 0.3133 - acc: 0.8992 - val_loss: 0.1735 - val_acc: 0.9447\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.92003 to 0.94474, saving model to model_digit.h5\n",
            "Epoch 7/10\n",
            "352/352 [==============================] - 28s 79ms/step - loss: 0.2678 - acc: 0.9154 - val_loss: 0.1613 - val_acc: 0.9516\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.94474 to 0.95165, saving model to model_digit.h5\n",
            "Epoch 8/10\n",
            "352/352 [==============================] - 28s 79ms/step - loss: 0.2420 - acc: 0.9212 - val_loss: 0.1592 - val_acc: 0.9514\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.95165\n",
            "Epoch 9/10\n",
            "352/352 [==============================] - 28s 78ms/step - loss: 0.2146 - acc: 0.9335 - val_loss: 0.1386 - val_acc: 0.9588\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.95165 to 0.95882, saving model to model_digit.h5\n",
            "Epoch 10/10\n",
            "352/352 [==============================] - 28s 79ms/step - loss: 0.1877 - acc: 0.9395 - val_loss: 0.1380 - val_acc: 0.9564\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.95882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTynIeqtKS8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(EPOCHS_digit), training_log.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(EPOCHS_digit), training_log.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(EPOCHS_digit), training_log.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(EPOCHS_digit), training_log.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss/accuracy\")\n",
        "plt.title(\"training plot digit\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"training_plot_digit.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1LDlDhVLlfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd0c4781-4e4b-46b9-d225-8b4cc9dc0304"
      },
      "source": [
        "correct = 0\n",
        "for idx,test in enumerate(test_input_digit):\n",
        "  test = np.expand_dims(test, 0)\n",
        "  model_digit.load_weights(\"model_digit.h5\")\n",
        "  predictions = model_digit.predict(test)[0]\n",
        "  label = np.argmax(predictions)\n",
        "  if (label == test_target_digit[idx]):  \n",
        "    correct += 1\n",
        "test_accuracy = correct/len(test_target_digit)\n",
        "print(\"test_accuracy_digit:\" , test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_accuracy_digit: 0.9773013871374527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sxai6O-MRKT",
        "colab_type": "text"
      },
      "source": [
        "# Letter Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI0YeXzJMcfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes_letter = 32\n",
        "EPOCHS_letter = 20\n",
        "BS_letter = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXbpXvzfMnt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_letter = np.array(data_letter, dtype=np.float) / 255.\n",
        "labels_letter = np.array(labels_letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhPv4FZAMyLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_input_letter, test_input_letter, train_target_letter, test_target_letter =  train_test_split(data_letter,\n",
        "                                                                              labels_letter,\n",
        "                                                                              test_size=0.05,\n",
        "                                                                              random_state=123)\n",
        "train_input_letter, valid_input_letter, train_target_letter, valid_target_letter =  train_test_split(train_input_letter,\n",
        "                                                                                train_target_letter,\n",
        "                                                                                test_size=0.25,\n",
        "                                                                                random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqRjesGVMyY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01eac926-9ec6-47b6-d36b-8129c555ab56"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "train_target_letter = to_categorical(train_target_letter, num_classes=num_classes_letter)\n",
        "valid_target_letter = to_categorical(valid_target_letter, num_classes=num_classes_letter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbj6efXRMyhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "aug = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYlj-JFJMylm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a581814-7d5d-4207-9f1f-fb8f1426016f"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "from keras.models import Model\n",
        "def build_model_letter(inputs):\n",
        "  x = inputs\n",
        "\n",
        "  x = Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation=\"relu\")(x)\n",
        "  x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "\n",
        "  x = Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation=\"relu\")(x)\n",
        "  x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x) \n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(500, activation=\"relu\")(x)\n",
        "  outputs = Dense(num_classes_letter, activation=\"softmax\")(x)\n",
        "\n",
        "  model = Model(inputs, outputs, name=\"LeNet\")\n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhu3ONexMyqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "488ae458-8909-4599-b4ec-aeaaac1ff87d"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "input = Input((28, 28, 1))\n",
        "model_letter = build_model_letter(input)\n",
        "\n",
        "opt = Adam()\n",
        "model_letter.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"acc\"])\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=\"model_letter.h5\",\n",
        "                             monitor=\"val_acc\",\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "batches = aug.flow(train_input_letter, train_target_letter, batch_size=BS_letter)\n",
        "training_log = model_letter.fit_generator(batches,\n",
        "                        samples_per_epoch=batches.n,\n",
        "                        steps_per_epoch=len(train_input_letter) // BS_letter,\n",
        "                        validation_data=[valid_input_letter, valid_target_letter],\n",
        "                        epochs=EPOCHS_letter,\n",
        "                        callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"LeNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               1225500   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                16032     \n",
            "=================================================================\n",
            "Total params: 1,267,102\n",
            "Trainable params: 1,267,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=1466, validation_data=[array([[[..., epochs=20, callbacks=[<keras.ca...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1466/1466 [==============================] - 123s 84ms/step - loss: 3.3946 - acc: 0.0498 - val_loss: 2.2212 - val_acc: 0.3349\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.33493, saving model to model_letter.h5\n",
            "Epoch 2/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 1.6572 - acc: 0.4843 - val_loss: 0.9504 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.33493 to 0.69178, saving model to model_letter.h5\n",
            "Epoch 3/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 1.0594 - acc: 0.6598 - val_loss: 0.6220 - val_acc: 0.7956\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.69178 to 0.79556, saving model to model_letter.h5\n",
            "Epoch 4/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 0.7534 - acc: 0.7503 - val_loss: 0.4762 - val_acc: 0.8415\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.79556 to 0.84151, saving model to model_letter.h5\n",
            "Epoch 5/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 0.6018 - acc: 0.8006 - val_loss: 0.3909 - val_acc: 0.8731\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.84151 to 0.87315, saving model to model_letter.h5\n",
            "Epoch 6/20\n",
            "1466/1466 [==============================] - 122s 83ms/step - loss: 0.5271 - acc: 0.8234 - val_loss: 0.3686 - val_acc: 0.8754\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.87315 to 0.87545, saving model to model_letter.h5\n",
            "Epoch 7/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 0.4621 - acc: 0.8455 - val_loss: 0.2999 - val_acc: 0.8999\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.87545 to 0.89992, saving model to model_letter.h5\n",
            "Epoch 8/20\n",
            "1466/1466 [==============================] - 118s 81ms/step - loss: 0.4180 - acc: 0.8592 - val_loss: 0.2657 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.89992 to 0.91098, saving model to model_letter.h5\n",
            "Epoch 9/20\n",
            "1466/1466 [==============================] - 118s 81ms/step - loss: 0.3837 - acc: 0.8693 - val_loss: 0.3069 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.91098\n",
            "Epoch 10/20\n",
            "1466/1466 [==============================] - 118s 81ms/step - loss: 0.3581 - acc: 0.8784 - val_loss: 0.2235 - val_acc: 0.9249\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.91098 to 0.92491, saving model to model_letter.h5\n",
            "Epoch 11/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 0.3321 - acc: 0.8859 - val_loss: 0.2050 - val_acc: 0.9330\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.92491 to 0.93296, saving model to model_letter.h5\n",
            "Epoch 12/20\n",
            "1466/1466 [==============================] - 122s 83ms/step - loss: 0.3107 - acc: 0.8932 - val_loss: 0.1913 - val_acc: 0.9346\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.93296 to 0.93462, saving model to model_letter.h5\n",
            "Epoch 13/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 0.2946 - acc: 0.8989 - val_loss: 0.2739 - val_acc: 0.9072\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.93462\n",
            "Epoch 14/20\n",
            "1466/1466 [==============================] - 118s 81ms/step - loss: 0.2748 - acc: 0.9051 - val_loss: 0.1798 - val_acc: 0.9403\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.93462 to 0.94031, saving model to model_letter.h5\n",
            "Epoch 15/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 0.2633 - acc: 0.9086 - val_loss: 0.1962 - val_acc: 0.9320\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.94031\n",
            "Epoch 16/20\n",
            "1466/1466 [==============================] - 118s 81ms/step - loss: 0.2516 - acc: 0.9135 - val_loss: 0.1832 - val_acc: 0.9388\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.94031\n",
            "Epoch 17/20\n",
            "1466/1466 [==============================] - 121s 83ms/step - loss: 0.2450 - acc: 0.9157 - val_loss: 0.1678 - val_acc: 0.9429\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.94031 to 0.94287, saving model to model_letter.h5\n",
            "Epoch 18/20\n",
            "1466/1466 [==============================] - 118s 81ms/step - loss: 0.2334 - acc: 0.9184 - val_loss: 0.1685 - val_acc: 0.9402\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.94287\n",
            "Epoch 19/20\n",
            "1466/1466 [==============================] - 118s 81ms/step - loss: 0.2280 - acc: 0.9221 - val_loss: 0.1373 - val_acc: 0.9519\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.94287 to 0.95194, saving model to model_letter.h5\n",
            "Epoch 20/20\n",
            "1466/1466 [==============================] - 119s 81ms/step - loss: 0.2188 - acc: 0.9235 - val_loss: 0.1444 - val_acc: 0.9508\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.95194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3_dyJgFMyvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "901734f9-67a6-4a65-ff85-bee46a3edd0d"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(EPOCHS_letter), training_log.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(EPOCHS_letter), training_log.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(EPOCHS_letter), training_log.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(EPOCHS_letter), training_log.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss/accuracy\")\n",
        "plt.title(\"training plot digit\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"training_plot_letter.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU9bn48c/3nDP7ZA8hkAAKiAhUZVHcRUHF9bZqtVq5SNHqta1X7c9W722lWrUK5VasdNVqtfa6XLdal2KkiEu1KogKyiZUFELInkwy2znf3x+TDAnZJvtAnvfrNa+Zs84zQzjPnO+qtNYaIYQQAjAGOwAhhBDpQ5KCEEKIJEkKQgghkiQpCCGESJKkIIQQIkmSghBCiCRJCmK/89BDD2FZVreO2b59O0op3njjjX6KqnsGI56DDjqI22+/vcPlVFx++eXMmTOnr0MTaaR7/7OE6IE5c+ZQXFzMQw891Cfnu/jiiznzzDO7dcyoUaPYtWsXeXl5fRLDYPjTn/7EvHnz6KuuRe+++y5+v79bxyxbtgzHcZLLV1xxBVu2bGHVqlV9EpMYfJIURNqIRqO43e4u9/P5fPh8vm6d2zRNCgsLexraAWnYsGHdPiYrK6sfIhHpRIqPRL+6/PLLefXVV/njH/+IUgqlFKtWrUoWnzz66KOcddZZBAIBfvzjH6O15sorr2TcuHH4fD7Gjh3Lf/3XfxGJRJLn3Lf4qHn5zTffZNq0afj9fqZPn867776b3Gff4prm5SeeeIJzzjkHv9/P2LFj29zNbNu2jdNPPx2v18uoUaNYvnw5s2bN4oorrujwM69atQqlFM8//zxHH300Xq+XKVOmsHLlyk6/q40bN3L22WcTDAYJBoOce+65bNmyJXnOefPmASS/x8svv7zDc61bt47jjjsOj8fDIYccwhNPPNFmn32LjyoqKvj6179OIBBg+PDh/PjHP2b+/PmtiotaFh/95Cc/4YEHHuC1115LxtRXd4Ni8EhSEP1q2bJlnHjiiVx00UXs2rWLXbt2cdxxxyW3//CHP+Sb3/wmH3/8MVdffTVaawoKCvjzn//MJ598wj333MODDz7InXfe2en7OI7DzTffzLJly1izZg0FBQVcdNFFxOPxTo+76aab+Pd//3c+/PBDvvGNb3DFFVewadMmALTWfO1rX6OmpobVq1fz/PPP88ILL7B27dqUPvsNN9zALbfcwtq1a5k5cybnnnsuu3btanffxsZGTj/9dMLhMK+99hqvvfYa9fX1zJ07l2g0ynHHHcd9990HkPwely1b1uG5zjrrLLKzs/nnP//Jww8/zJIlSygrK+s03gULFrBu3Tr++te/snLlSr744gueffbZDvf/f//v/3HppZdy7LHHJmO6+OKLU/puRBrTQvSz2bNn6/nz57dat23bNg3o2267rcvj/+d//kePHz8+ufzggw9q0zRbLQP6/fffT657++23NaA//fTTVu/3+uuvt1peunRp8ph4PK6DwaD+zW9+o7XWesWKFRrQmzdvTu5TUVGhfT6fXrhwYYfx/v3vf9eAvv/++5PrYrGYHj16tP7Rj37Ubjz333+/9vl8es+ePcljSktLtdfr1X/84x+11lo/8sgjOpX/sr///e91IBDQlZWVyXUfffSRBvRPf/rT5LoxY8Yklzdt2qQBXVJSktwejUZ1cXGxnj17dnLd/PnzWy0vXLhQn3zyyV3GJPYfUqcgBtXRRx/dZt3vf/977r//frZv304oFCIej7eq3GyPUoojjjgiuTxy5EgAdu/ezaGHHtrhcUceeWTytWmaFBQUsHv3bgA2bNhAfn4+48ePT+6Tm5vb6flaOvbYY5OvLcvi6KOPZv369e3uu379eiZNmkR+fn5y3fDhwzn00EM7PKYjGzZs4LDDDiMnJye5bsqUKZ3WB2zYsAGAY445JrnO5XIxY8YM6urquvX+Yv8mxUdiUAUCgVbLTz75JN/5zne4+OKLefHFF1m7di233HILsVis0/MYhoFpmsllpRRAl8lk34ptpVSrY5rPM1QMtc8r2pKkIPqd2+3Gtu2U9l29ejVTp07lhhtuYPr06RxyyCFs3769fwPswKRJk9izZw9bt25NrquqqkrWOXTl7bffTr6Ox+P885//ZNKkSe3uO3nyZDZs2EB5eXly3e7du9m4cSNTpkwB9iawrr7LSZMm8cknn1BdXZ1ct379empqajo9BuAf//hHq5jff//9Tt+rO/+2Yv8gSUH0u4MPPpj333+frVu3Ul5e3umv/kMPPZSPPvqI5557jq1bt7Js2TKefvrpAYx2rzlz5nDEEUcwb9483n33XdatW8e8efOwLCulX9R33XUXL774Ip988gn/8R//wZ49e7jmmmva3ffSSy9l2LBhXHzxxaxZs4b333+fb3zjGxQVFSUrbw8++GAA/vKXv7Bnzx7q6+s7PFdGRgaXXXYZ69at4+233+Zb3/pWp814DznkEM4991y+853v8Nprr7FhwwauuuoqamtrO/2sBx98MJ9++inr16+nvLy8VSsxsX+SpCD63fe//33y8/M54ogjGDZsGG+++WaH+1511VXMmzePBQsWMHXqVN555x1+8pOfDFywLSileOaZZwgEApx44omcc845nHnmmRx66KF4vd4uj//5z3/Oj3/8Y4488kjefPNNnnvuuWRdx758Ph8rVqzA4/Fw0kkncfLJJxMIBHj55ZeTdwhHHXUU//mf/8lVV11FQUEB3/3ud9s9l9/v58UXX6SiooKjjz6ab37zm1x//fUUFBR0Gu+DDz7IlClTOPPMM5k1axZFRUWcdtppnX7WhQsXctRRR3HccccxbNgw/vd//7fL70WkN6W1zLwmRKrq6uooLi7m9ttv53vf+167+6xatYpTTjmFHTt2UFxcPMAR9h3btpk4cSLnnXceS5cuHexwxACR1kdCdOIvf/kLlmVx2GGHUVZWxq233opSiosuumiwQ+tzq1evpqysjKlTp1JXV8cvfvELtm/f3mknOXHgkaQgRCcaGhq47bbb2L59O4FAgOnTp/PGG28wfPjwwQ6tz9m2ze23386WLVtwuVxMmTKFv//973zlK18Z7NDEAJLiIyGEEElS0SyEECJJkoIQQoikAalTiEajLFq0iHg8jm3bHHPMMW0q6latWsUjjzxCbm4uAHPnzmX27Nldnnvnzp09iik/P79VR6F0k+7xQfrHKPH1jsTXO+kcX0dNo2GAkoLL5WLRokV4vV7i8Ti33HILRx55JBMmTGi133HHHcfChQsHIiQhhBDtGJDiI6VUsgOMbdvYti1jrAghRBoasNZHjuPwwx/+kNLSUs444wwuu+yyVttXrVrFn//8ZzIzMxkxYgTz589vNWJks5KSEkpKSoDEMALRaLRH8ViW1eVY+4Mp3eOD9I9R4usdia930jm+zmY4HPAmqaFQiJ///OcsWLCA0aNHJ9fX1dXh9XpxuVy88sorvPXWWyxatKjL80mdwuBJ9xglvt6R+HonnePrrE5hwFsfBQIBJk+ezAcffNBqfUZGBi6XC4DZs2fz2WefDXRoQggx5A1IUqitrSUUCgGJlkgffvghRUVFrfapqqpKvn7vvff26zFjhBBifzUgrY+qqqpYvnw5juOgtebYY49l+vTpPP7444wbN44ZM2bw0ksv8d5772GaJsFgsMMhhoUQQvSf/X6Yi57UKegv/4V33TuEZ52N8ge6PmAQpHN5ZLN0j1Hi6x2Jr3fSOb60qlNIC+W7aXjmT1D6xWBHIoQQaWVoJoXCRH2FlqQghBCtDM2kkD8cLEvuFIQQYh9DMiko08QcMQq968vBDkUIIdLKkEwKANbI0XKnIIQQ+xiyScEsHgN7dqHTtBu6EEIMhiGbFKyiMWDbUF462KEIIUTaGNpJAaQISQghWhiyScEsSgzGJ5XNQgix15BNCkYgCFm5sFvuFIQQotmQTQoAFBahS+VOQQghmg3ppKBGFMOuL9jPh38SQog+M6STAoXF0FAPdTWDHYkQQqSFIZ0UVNMYSNICSQghEoZ0UpCB8YQQorWhnRRy8sDtAWmWKoQQwBBPCsowmlogyZ2CEELAEE8K0FSvIElBCCEASQqJeoWKMnQ0MtiRCCHEoJOkUFgEWkNZ9+d6FkKIA401EG8SjUZZtGgR8Xgc27Y55phjuOiii1rtE4vFuO+++/jss8/IyMjguuuuo6CgoN9jU4XFaBJjIKnig/v9/YQQIp0NyJ2Cy+Vi0aJFLFmyhMWLF/PBBx+wadOmVvusXLmSQCDAL3/5S84++2weffTRgQgNCkaCUlKvIIQQDFBSUErh9XoBsG0b27ZRSrXa57333mPWrFkAHHPMMXz88ccDMvyE8nggd5gkBSGEYICKjwAcx+GHP/whpaWlnHHGGRxyyCGttldWVpKXlweAaZr4/X7q6urIzMzs/+BGFEuzVCGEYACTgmEYLFmyhFAoxM9//nM+//xzRo8e3e3zlJSUUFJSAsBdd91Ffn5+j+KxLCt5bN3Bh9Cw4jnycnMTfRfSQMv40lW6xyjx9Y7E1zvpHl9HBiwpNAsEAkyePJkPPvigVVLIzc2loqKCvLw8bNumoaGBjIyMNsfPmTOHOXPmJJfLy8t7FEd+fn7yWCcrDyJhyjdvROUN69H5+lrL+NJVusco8fWOxNc76RzfyJEjO9w2ID+La2trCYVCQKIl0ocffkhRUVGrfaZPn86qVasAePvtt5k8eXKbeof+IgPjCSFEwoDcKVRVVbF8+XIcx0FrzbHHHsv06dN5/PHHGTduHDNmzODUU0/lvvvu43vf+x7BYJDrrrtuIEJLGJFIULr0S9TkqQP3vkIIkWYGJCmMGTOGxYsXt1l/8cUXJ1+73W5uuOGGgQinrYxs8AfkTkEIMeSlR63qIFNKQaG0QBJCCEkKTWRgPCGEkKSwV2ExVFeiGxsGOxIhhBg0khSaqKbKZkplwh0hxNAlSaGZTM0phBCSFJLyC8E0pV5BCDGkSVJooiwLhhXKnYIQYkiTpNBSYTHskqQghBi6JCm0oAqLoWwX2rYHOxQhhBgUkhRaKiwGOw7luwc7EiGEGBSSFFpQhc3NUqUISQgxNElSaEmapQohhjhJCi2oQBAys6WyWQgxZElS2JcMjCeEGMIkKexDNTVL1VoPdihCCDHgJCnsa0QRNNRDfe1gRyKEEANOksI+9k7NKQPjCSGGHkkK+5IWSEKIIUySwr5yh4HLLX0VhBBDkiSFfSjDgOFFaGmWKoQYgiQptEMVFsmdghBiSLIG4k3Ky8tZvnw51dXVKKWYM2cOZ511Vqt91q9fz+LFiykoKABg5syZXHjhhQMRXluFxfD+W+hYFOVyD04MQggxCAYkKZimybx58xg7diyNjY3cdNNNHH744RQXF7fa77DDDuOmm24aiJA6V1gE2oGyXVA0ZrCjEUKIATMgxUc5OTmMHTsWAJ/PR1FREZWVlQPx1j2iRjQ3S5UiJCHE0DIgdwotlZWVsW3bNsaPH99m26ZNm7jxxhvJyclh3rx5jBo1qs0+JSUllJSUAHDXXXeRn5/fozgsy+rwWB0MUAb4aisJ9vD8vdVZfOki3WOU+HpH4uuddI+vI0oP4HgO4XCYRYsWcf755zNz5sxW2xoaGjAMA6/Xy5o1a3jooYe49957uzznzp07exRLfn4+5eXlHW63f7gQdcgkjCu+36Pz91ZX8aWDdI9R4usdia930jm+kSNHdrhtwFofxeNxli5dyoknntgmIQD4/X68Xi8A06ZNw7ZtamsHcaiJwmK09GoWQgwxA5IUtNb85je/oaioiHPOOafdfaqrq5OD0G3ZsgXHccjIyBiI8NqlRhRDqQyMJ4QYWgakTmHjxo2sXr2a0aNHc+ONNwJwySWXJG+tTj/9dN5++21WrFiBaZq43W6uu+46lFIDEV77CosgEoaqCsjd/8oFhRCiJwYkKUycOJEnnnii033mzp3L3LlzByKclKjCYjQkWiBJUhBCDBHSo7kjMjCeEGIIkqTQkawc8Pmlr4IQYkiRpNABpZS0QBJCDDkpJ4W6urr+jCMtqcIikNFShRBDSMpJ4ZprrmHx4sW8/fbbxOPx/owpfRQWQ3UFOtww2JEIIcSASDkpLF++nClTpvDcc89x5ZVX8tvf/pZPP/20P2MbdKqwKPFid896TQshxP4m5SapmZmZnHXWWZx11lns3LmT1atX88tf/hKlFCeeeCKnnnoqw4YN689YB15zC6RdX6DGtB2rSQghDjQ9qmiurq6murqaxsZGhg8fTmVlJT/4wQ949tln+zq+wTVsBBiGtEASQgwZKd8p7Nixg9dff5033ngDj8fDySefzJIlS8jLywPgggsu4MYbb+SrX/1qvwU70JTLBfmF0ldBCDFkpJwUFi1axPHHH88NN9zQ7rDXBQUFbWZTS1eOoykvC6PRKKOLoTRGFIM0SxVCDBEpJ4Xf/e53WFbnu1988cW9DmggfPmvGB/88wtmzc0gI8vsdF9VWIRevwbt2Cij832FEGJ/l3KdwsMPP8zGjRtbrdu4cSMPPfRQX8fU77LzEhf3qooUmtYWFkM8DuVl/RyVEEIMvpSTwptvvsm4ceNarRs7dixvvPFGnwfV34IZBm63QXWl3eW+qlCm5hRCDB0pJwWlFI7jtFrnOM5+Od+AUor8Ag9VFV0nBZr6KkhlsxBiKEg5KUycOJHHHnssmRgcx+HJJ59k4sSJ/RZcf8of7qWuxiYe7zypqWAmZGRJZbMQYkhIuaJ5wYIF3HXXXVx11VXJuUdzcnL44Q9/2J/x9Zthw71oDTVVNnnDuvgaCovQMgaSEGIISDkp5OXlcffdd7NlyxYqKirIy8tj/PjxGMb+OdBqfoEHgOrKeJdJQRUWo9e+PRBhCSHEoOrWzGuGYTBhwoT+imVA+QMWPr+iOqV6hWKor0XX1aIyMvs/OCGEGCQpJ4WGhgaefPJJNmzYQF1dXasK5l//+tf9Elx/y86zqEqlBdKIpqk5d38BGZP6PS4hhBgsKZf93H///Wzbto0LL7yQ+vp6vvWtb5Gfn8/ZZ5/dn/H1q5xck8aQQyTsdL5ji4HxhBDiQJZyUvjwww/5/ve/z1FHHYVhGBx11FFcf/31vP766/0ZX7/KzkvcKHXZNDVvGFguaYEkhDjgpVx8pLXG7/cD4PV6aWhoIDs7m9LS0i6PLS8vZ/ny5VRXV6OUYs6cOW3GSdJa8+CDD7J27Vo8Hg/XXHMNY8eO7ebH6Z6sHBOlEpXNhUWuDvdThgnDR6J3S1IQQhzYUk4KY8aMYcOGDXzlK19h4sSJ3H///Xi9XkaMGNHlsaZpMm/ePMaOHUtjYyM33XQThx9+OMXFxcl91q5dS2lpKffeey+bN2/m/vvv58477+zZp0qRZSkysozUO7Ht2N6v8QghxGBLufjoqquuSk6is2DBAtxuN6FQiO9+97tdHpuTk5P81e/z+SgqKqKysrLVPu+99x4nnXQSSikmTJhAKBSiqqqqO5+lR7JzLWoq7S57ZqvCYigvRcdi/R6TEEIMlpTuFBzHYdWqVZx//vkAZGVlcfXVV/foDcvKyti2bVub4bcrKyvJz89PLufl5VFZWUlOTk6r/UpKSigpKQHgrrvuanVMd1iWRX5+PqPG1PL5Z2W4rSyyctwd7t94yGHUvuCQEw9jpXB31FvN8aWzdI9R4usdia930j2+jqSUFAzDYMWKFXz961/v1ZuFw2GWLl3K5Zdfnqyf6K45c+YwZ86c5HJ5eXmPztPcK9tyJ4qOPttSzqiDO04KOpgFQNUnH6F8GT16z57El87SPUaJr3ckvt5J5/hGjhzZ4baUi49OOukkXnnllR4HEY/HWbp0KSeeeCIzZ85ssz03N7fVF1hRUUFubm6P3y9VGZkGppWobO7U8KaB8aRZqhDiAJZyRfOWLVt4+eWX+ctf/kJeXh5K7Z2x7NZbb+30WK01v/nNbygqKuKcc85pd58ZM2bw8ssvc/zxx7N582b8fn+boqP+oAxFdq7VZWWz8vogJ1+apQohDmgpJ4XZs2cze/bsHr3Jxo0bWb16NaNHj+bGG28E4JJLLkneGZx++ulMnTqVNWvWcO211+J2u7nmmmt69F49kZNrsnVTBNvWmGYn03MWFskQ2kKIA1rKSWHWrFk9fpOJEyfyxBNPdLqPUoorrriix+/RG9l5JtqB2iqbnPyOvxJVWIz+x0q01q3ulIQQ4kCRclJYuXJlh9tOPfXUPglmsGTnNvVsruw8KTCiGMKNUFMJ2XkDFJ0QQgyclJPCvsNZVFdXU1paysSJE/f7pODzG3h9iuqKOODpcD9V2DQw3q4vJCkIIQ5IKSeFRYsWtVm3cuVKvvzywKh4zc5NYcTU5oHxSr9EHXbEAEQlhBADq1cz5MyaNavTYqX9SU6eSUO9QzTSyYip2bng8YFUNgshDlApJwXHcVo9wuEwJSUlBAKB/oxvwGTnmgCd3i0opaQFkhDigJZy8dEll1zSZl1ubi5XXXVVnwY0WJorm6sr4gwf0cmIqYVF6M3rByosIYQYUCknhfvuu6/VssfjITPzwJma0nIlRkytTqVe4Z3X0OHGRIc2IYQ4gKScFEzTxO12EwwGk+vq6+uJRqMDMhzFQMjOtSj9MtZpP4S9U3PuhDHjBjQ+IYTobynXKSxZsqTNcNeVlZX8/Oc/7/OgBktOnkksqmkIdVLZnGyBJPUKQogDT8pJYefOnYwePbrVutGjRx8wTVKhRWVzZ+MgFYwAZcgYSEKIA1LKSSEzM7PN1JulpaVkZPT/MNIDJSPLxDRp6sTWPuVyQ36BNEsVQhyQUq5TOOWUU1i6dCnf+MY3GD58OKWlpTz++OP7fW/mlgxDkZVrplTZLMVHQogDUcpJ4atf/SqWZfHII49QUVFBfn4+p5xySodDYe+vsnMttm+O4Ngao4MRU9WIYvSnH6IdG2WYAxyhEEL0n5STgmEYnHfeeZx33nn9Gc+gy8kz+Wwj1NbYyb4LbRQWQywKe3bD8I5nMBJCiP1NynUKzz77LFu2bGm1bsuWLTz33HN9HtRgSo6Y2kllszr0K6AU+s2SgQpLCCEGRMpJ4cUXX6S4uLjVuuLiYl588cU+D2ow+fwKj1d1XtlcMAKmHoN+7SV0uHEAoxNCiP6VclKIx+NYVuviFMuyiEajfR7UYFJKkZ1rdjliqnH616AhJHcLQogDSspJYezYsfztb39rtW7FihWMHTu2z4MabNl5FqE6h2i0405satxEGH8Y+pXn0HYXrZWEEGI/kXJF8/z587n99ttZvXo1w4cPZ/fu3VRXV/PjH/+4P+MbFDlNndhqKm2GFXacN43Tv4bzqzvRa/6BOuqEgQpPCCH6TcpJYdSoUSxbtoz333+fiooKZs6cyfTp0/F6vf0Z36Bo2bN5WGHHI6ZyxFFQMBK94hn0jONl3mYhxH4v5aQA4PV6Of7447v9Jr/61a9Ys2YNWVlZLF26tM329evXs3jxYgoKCgCYOXMmF154Ybffp6+43AbBDIPqyo4rmwGUYaJO+zf0o7+GzethwpQBilAIIfpHyknBtm3+9re/sWHDBurq6lptu/XWWzs9dtasWcydO5fly5d3uM9hhx3GTTfdlGo4/S47z6RsV7zTEVMB1LGnop97FGfFs5iSFIQQ+7mUK5r/+Mc/UlJSwqRJk/jss8+YOXMmNTU1TJ48uctjJ02a1GrI7f1BTq5FNKJpbOhkxFRAeTyoU86Cdf9E75KhL4QQ+7eU7xTeeecd7rjjDvLz83niiSc466yzOOKII/jd737XJ4Fs2rSJG2+8kZycHObNm8eoUaPa3a+kpISSkkQz0Lvuuov8/PwevZ9lWZ0f64T5aM0X2FE/+WM6H/TPOf8y9vztaTyvv0zmNX1zt9NlfGkg3WOU+HpH4uuddI+vIyknhWg0Sl5eHgBut5tIJEJRURHbt2/vdRAHH3wwv/rVr/B6vaxZs4YlS5Zw7733trvvnDlzmDNnTnK5vLy8R++Zn5/f6bGO1hgGfL69moycSJfnU8ecSuPfXyIy9wJUZk6PYupOfOkg3WOU+HpH4uuddI5v5MiOh+dJufioqKiIrVu3Aok+C08++SRPPfVUn8y65vf7k62Ypk2bhm3b1NbW9vq8vWGYiqwck6ouKpubqdPOAzuOXvlCP0cmhBD9J+WkcPnll2MYid3nz5/Ptm3beP/99/n2t7/d6yCqq6vRWgOJ8ZQcx0mLeRqy8yxqqmwcR3e5ryoshiOORq96CR0JD0B0QgjR97osPvrwww+ZNGkS48ePT64bMWJEtzqt3XPPPclWS1dffTUXXXQR8XjiF/jpp5/O22+/zYoVK5LzQF933XVp0eY/J9dk2yaoq7HJyum6pM0442s4H7yDfutV1ClnD0CEQgjRt7q80j3//PMsW7aMQw89lGnTpjFt2rRuFxldd911nW6fO3cuc+fO7dY5B0J23t5ObKkkBcYdBmMPTQx9cfJcmWtBCLHf6fJK99///d9EIhE++ugj1q5dy9NPP00gEGDq1KlMmzaNCRMmJIuVDjT+gIHbo7qeia2JUiox9MVv7oK178D04/o5QiGE6FsptT7yeDzMmDGDGTNmAPD555+zdu1aHnvsMb788ksmT57M2WefzSGHHNKvwQ605IipnQyj3cbUmTCsEOdvT2NMOzYtisGEECJV3Rrmotno0aMZPXo0//Zv/0ZDQwPr1q2jsfHAnFcgJ8+ibFeYWEzjcnV9gU8OffHn38LWT2D8pAGIUggh+kbK5T4ff/wxZWVlAFRVVXHffffxq1/9img0yrHHHsvhhx/eb0EOpuzkiKmp3y2o42ZDIAPnb8/2V1hCCNEvUk4KDzzwQLLu4OGHH8a2bZRS/Pa3v+234NJBcsTUFOsVAJTHi5p1Jqx7B136ZX+FJoQQfS7lpFBZWUl+fj62bbNu3TquuuoqrrzySjZt2tSf8Q06t8cgEDSo7mTO5vaoU88G00SXHFhzWAshDmwpJwWfz0d1dTUbNmyguLg42QO5ub/BgSw7L1HZ3NzBLhUqMycxgupbK9F1Nf0YnRBC9J2Uk8LcuXO5+enlWx8AACAASURBVOabuffeeznjjDMA+PTTTykqKuq34NJFTq5FJKwJN6aeFADUaf8GsSj67zL0hRBi/5By66OvfvWrHH300RiGQWFhIQC5ublcffXV/RZcutjbiS2Oz+9O+Tg1YhQcfhT67y+iz7gA5fH0V4hCCNEnutXrbOTIkcmE8PHHH1NdXc3o0aP7JbB0kpltYhik3ImtJeOMr0F9LfofK/shMiGE6FspJ4VFixbx6aefAvDss8+ybNkyli1bxtNPP91vwaUL01RkZptUd6cTW7NDJsNBhySGvnC6n1SEEGIgpZwUduzYwYQJEwB49dVXWbRoEXfccQevvPJKvwWXTrJzTaqrbHQKI6a2pJRCnf41KNsJ697tp+iEEKJvpJwUmlvelJaWAlBcXEx+fj6hUKh/IkszOXkWdhzqajufnrM9atqxkFeAs+KZfohMCCH6TsoVzYceeih/+MMfqKqq4qijjgISCSId5j0YCC0rmzOzuzf6qTKbhr547PforZ+ixk3sjxCFEKLXUr5T+M53voPf72fMmDFcdNFFAOzcuZOzzjqr34JLJ4Gggcud+oip+1LHzwF/AGeFDH0hhEhfKd8pZGRkcOmll7ZaN23atD4PKF01j5jao8pmQHl9qJPPRL/8FLpsF6pgRB9HKIQQvZdyUojH4zz99NOsXr2aqqoqcnJyOOmkkzj//POxrB4Ntrrfyc412fxJnHhMY6UwYuq+1KnnoFc8iy55DnXpgd+/Qwix/0n5av6nP/2JrVu3cuWVVzJs2DD27NnDU089RUNDA5dffnk/hpg+cvIs0BFqqmzyCrqfCFV2LuqYk9FvlqDPuxQVzOyHKIUQoudSvrK9/fbbLFmyJFmxPHLkSA4++GBuvPHGtEoKWmvC4TCO43Q6wc3u3buJRCLdOrc/w2HCVyBmN9LQ0LOpNvXZl6BHjYedX2AUH9Sn8fUlrTWGYeD1emWiICGGkJSTQncGgxtM4XAYl8vVZZGWZVmYZvcv7CNG2pgW+P09nH/Z70dPmQrRMHi9qA6mMu1pfH0pHo8TDofx+XyDGocQYuCk3Pro2GOP5e677+aDDz7giy++4IMPPmDJkiUcc8wx/RlftzmO0691HKYFdryXCTIrB2wHynendbK1LAvH6X6/DCHE/ivlq+dll13GU089xQMPPEBVVRW5ubkcd9xxXHjhhV0e+6tf/Yo1a9aQlZXF0qVL22zXWvPggw+ydu1aPB4P11xzDWPHju3eJ2nS30UdpqWIRTWOozGMnr2X8vrQuflQuQeqytE5+WlbRJOucQkh+kenSeHjjz9utTx58mQmT56M1jp5sfj000+ZMmVKp28ya9Ys5s6dy/Lly9vdvnbtWkpLS7n33nvZvHkz999/P3feeWd3PseAsczE57bjGsPd8wumysxGx2NQW524/cjK6asQhRCixzpNCr/+9a/bXd+cEJqTw3333dfpm0yaNCk5v3N73nvvPU466SSUUkyYMIFQKJRs9ppuzKZvLB4HV+qjaLcvJx9sO3G3YFqo4NDoHS6ESF+dJoWOftn3teapPpvl5eVRWVnZblIoKSmhpKQEgLvuuqvVcZBotZNqnUJP6x4sS+M47R9fU1PD008/zYIFC1I6lx4+EnvXDi67fD6//s1vySnc26ktlfiuvfZaTjvtNM4999zUP0A3eDyeNt9xM8uyOtyWDiS+3pH4eifd4+vIftfrbM6cOcyZMye5XF5e3mp7JBJJqdWOZVk9nkrUMDWxqCYWi7Upc6+srOTBBx9k3rx5rdbH4/EOL/I6v5BHlv0CGuqINWSi3J6U43McB9u2+21a1Egk0uY7bpafn9/htnQg8fWOxNc7+8bnOA6xWIx4PE4sFmtVDA97S2BSfXa5XLhcrh7FNnLkyA63pUVSyM3NbfXlVVRUkJub2+vzOo/9Hr1jW/vblOpRyx816mCsry0kGtHEYxrXPvUKd955J//617847bTTcLlceDwesrKy2LJlC2+88Qbf+ta32LlzJ5FIhIULF3LZZZehTJOZ53+dF+//LaFdpcy78SZmHnMM7777LoWFhfzhD39IqVno66+/zk9/+lNs2+aII47gZz/7GR6PhzvvvJMVK1ZgWRYnnXQSt9xyC88//zy/+MUvMAyDzMzMITEvRrrQWmPbNrFYLHlxaP5bbPm87+t99/H5fD2+KPQk5sbGRurq6qitraW+vh7Y23TaNM0uX7dcZxgGWuvkj5rm5+bHvsv7rnMcB7/fT21tLY7jJM/V8nXLde2tBzAMIzG8fScPo6nZ+L77tvw3bH40X/Cb/10bGxuT62y7b+dTmT59Oscff3yfnhPSJCnMmDGDl19+meOPP57Nmzfj9/vTsj6hmculME1FQ8ghaCZeN/uv//ovNm7cyCuvvMJbb73Fv//7v7Ny5crkDHVLly4lJyeHxsZGzj77bM4666ymBKhgWCH8ayvbtm/nN7/+NYsXL+aqq67ixRdf5IILLug0pnA4zPXXX8/jjz/OuHHjuPbaa3n44Ye54IILeOmll1i9ejVKKWpqagC45557ePTRRxkxYkRynWif4zg0NDRQV1dHfX099fX1hEKh5H/05ju1fS9iLdftu72vuN1uAoFAu49gMJh83VVRpOM4hEIh6urqkhf+WCxGWVlZcl1f3o2qHv4o667mC7lhGK1et6wXdZqTrqPR2mmVhFsm447Ob1ouTMvCsCxM04VhWRimG7fXh9eXhWFaKMtCGRbKTDwwTDR7Y2h+j8R0LU3LGjQa3fSMbn5N4nV2Yb98ZwOSFO655x42bNhAXV0dV199NRdddFHyD+z0009n6tSprFmzhmuvvRa3280111zTJ+9rfOPKDrf1pvgIwB80qK+1CdU7BDOMDpunHnnkka2mLP3DH/7ASy+9BCRGmd22bVvyrki5PZBbwKgRhRyWn4N2HA4//HB27NjRZTxbt25l9OjRjBs3DoCvf/3r/PGPf2TBggV4PB6+//3vtyp6mzFjBtdffz3nnnsuZ555Zo+/h57QWhOJRNr9ddX8uuVzR+ua78Tcbjdutzv5uvk5EonQ2NiY3N7ehbH5YlhfX9/qot/yEQqF2lwYTNPE5XJ1+Ku4s23Nj2AwSENDQ7vFA/u+3ne5+VdoKBRKPnbt2kV9fX27fUs8Hk+rhOH1+WhobKSuNnHBbwi1Pc7j9eH2BfD4syjIH4nLF8TyBjC8AQyPHwfVItnFcWyHuB3HsW2ceLzFXYCNthPLjh1HOzaO7aBRaGXgoHAw0EphY+BgYKMS58fAxsDWiW1xFHGtsLUCwyTmJC6UtjJwtEJDYl+t0CpxkW2+qO593aM/2sT3n4iaxBkNtGqnq5fT9Ij15I1Sd/7wICf0w3kHJClcd911nW5XSnHFFVcMRCh9xjQV/qBJqM6mIeQQCO799dGS3+9Pvn7rrbd4/fXXef755/H5fFx44YVthrJQXh8enw/dGIKKMgzD6NUvS8uyeOGFF3jjjTd44YUXePDBB3nyySe5++67WbNmDa+++ipnnnkmL730Uq+K7BzHIRwO09DQ0OmjsbGRhoaGbv1KNAwDy7KSPdWbL7j19fVEo9FkgumKaZrJpGFZVoexWJZFRkYGwWCQUaNGEQwGCQaDyXXBYBCPx9NhHw6tNXEHYo5DzNbEHJ18jrdYdgczqKuqTi7H93lueVzLYxPPDnEnk7gDtlsTtzTxDE3cdhJNnWONGPFw8mHFw7hCYVy1tbidPbidCFHlJmx6CRt+wu68ptdeGg0fYdOLo5ouD+GmR1Kk6dHhvxiwt2meqcBQCtNIPBvJZYWlwDSaXysMAyxDYTbtbxoKd4vXZvNxBvi9PiKRMIZSKAUKMFTietL8HgpQbV6DosU+TetaxrbvusS5VfJchgKz+dlQrfZtXs7LyaG2pib5uff9HppjVs2xNcWnSLwwSKzcu77lMYn37w9pUXy0v3K5FD6/QWODQ7hR4/MrAoFAsrx1X3V1dWRlZeHz+diyZQtr1qxp/8SGiZFXgFNRBo0NKcUybtw4duzYwbZt2zj44IN56qmnOOaYYwiFQjQ2NnLKKacwdepUTjzxRBobG9m+fTsTJkxgwoQJlJSUsHXr1nbLp8vKyvj888/b3E47jkM8HqempiZ5sW/vQm8YBoFAAL/fTzAYpKCgAL/fj9/vT1aU7XvBb/mc6nAfjuMQjUaTSSIajeL2eCjdvYeGcJjGcIRwJEI4sjeJ+AM5ZHj9GG4/yuMDlw/b5SeuTGIOlNuanbZD1NZEqzXRcoeo00A0HiLmJNa3d7GPdXPK1s4YKnGRdJkq8dz02mUkls2mdaah8FgGlmFiGm4sI4ilFJaZuJBa5t4LsNXOw2UmLlqW0bSvocjLzqahvjZ5jKvF/s0X6X0vkO1d/PtL+lc0Z1BuDd74ZT0lSaGXPF4Dx9ZEwg6Gmag0P+qoozj11FPxer2tmqTNmjWLRx55hJNPPplx48Z1Oh+FkZ2LE41AuAHdxWgkWmtcLheLFy/m29/+NvF4nClTpnDeeeexY8cOrr322uQdyfXXX09tbS133HEHO3bsQGvN0UcfzejRo2lsbGx1XqUUdXV1bNmypd0KuIyMDDIyMhg+fHjyQr/vw+12d9kr2nY0jTGHxrhDQ9NzY6NDYzxKYyyc3NbyORx3iMQdIrYm2vxsO0Tie59jTh2J31W+psc+okCr/B0DEvUrLkPhNhMPl2ngNhUeS+EyDNyWImhYTRdnI/Fs7r1gW0brZbdptLmgu0xFfm4OobqapmUjcdE1W+9n9rDXfF/Iz8+hvLxvK0dF+lM6nQffScHOnTtbLTc0NLQqsulIb+sUWtJaE6p3iMc0wQyzR3Mt7MuyrESRyJ5SaAjBsEJsjzdZaRlvVWbrtPmVrpRq1dKjvefm/TrT2fe57y81rTXhuKY2EqcmbFMbsakJx6mJ2NSGbWoiNnUttjVf5KN2an+ChgKfy8BnGXibHomLddtnj6nIyQgSjzS2u735gu822752mapff+E2S/9fuhJfb6RzfGnfJHV/p5TCHzCor3UI1dsEM81WLZK6o2XRTCQSIe7xJyrW6kPo+lByv+YLe3P5+r4X/JaVkz2ltSZmO+yqi1IbsakON13QwzbVkTgRXUFZbQO1TRf+uojd4QXeZSgyvSaZHpMsj0lh0I3fnbjA+1xG8mKfvOi72m5zm937TOn8n1KIdCVJoY8YhiKQkWiR1NDUIkl1cuvf8uLf8td/PB5v9avfMAwsl5u7bruVNR+sQ1kmqqnFwxVXXMHFF1/c7VgdrYnaGttpemianjW2Q9Nz4vWnu+r43bq2TVa9liLH7yboUuT4LA7K8ZDpscjymGR6TbI8VtNzYtlntV8RL4RIL5IU+pBpJu4YQvUODQ0O/kDrC6HWmng8TmNjI5FIpFUTwOYWNj6fD9M0k61bmjvOLF7ycyjdAcqAwmJUCkNgJFrBJBJAxHaIxhPPsXZ+zaum1hHNLTzcrsTzuFwP/3nsiOTFPdtrkekx8ViG/BIX4gAkSaGPudwGXj+EGxwipsbrS/R8DIfDhMNh4vE4Sik8Hk+yhU1z2X9L+9Z5KJcLXTASdn8JZTvRhUUoY+8xjk60fInsU9nqtLjraK70zHAr3JaBpVq3ImmPX3mZmEIdjRDiwCBJoR94PAonrmgIhWlojBKPR5MthDIzM/F4PMk7gO5QHi86vxC9Zxfh8gqiwRwijk62wEnupxIVp0G3gbup0tVtGoPakkUIsX+QpNDHmqewbGxsTMwT7Rh4vT78fl+vZoRzdKLZZr3jIhQswgFojGMCHpeB32fhMRMJwNXNClkhhGgmSaEPOI6THFKhuWetx+PB6/ESiVjggGF0f77lZCKI2oSiDo7WGEoR8JgElI23rhIz3ABuD+TkoTyBvv5oQoghpvtlGAJIVOJGo1Fqa2spLy+ntrY22aLoxRdfJDs7G6/PSyBooh0I1bftS9DSvHnzqKmpSfR5iNrsqg2zvSrCrroooahDwG0wIsPNQTkehgfdBAM+zOEjYdgIcBzYvRO9+0t0dP/rQSmESB+SFHogFotRWVlJVVUV4XAYr9dLTk4Oubm5xONxHnnkkeS+lqXwBQ0i4RiNofYTg9aa3zzwEGHTx7amRFAXjrdJBAG32apCWCmFCgRh5OjELG6RCOzcgS4vQ/fT/ApCiAPbAV18dP97u9lWFW53W0+H7j0o28PXDrbQWrdbadzRfAqbN2/hhedX8R/f+Ra7d+8iEolw2fwFnHPhNwhFHb5+xkn87rFnMWJhrv32Ao45ZibvpTCfwqOPPsqjjz5KNBrloIMO4t5bb8EXqmXPF//ipv+5l8937gLgZz/7GUcddRRPPvkkv/3tbwE47LDD+OUvf9nt70AIceA6oJNCX9NANBbFthU5OTm43W0nae5oPoVRo0bREHK49SdLyC7IZldNPVd+46tMPek0igryMJViTLaHxgabf23fxu9/91uWpDCfwplnnsk3v/lNAO6++24e+1sJC+Zdxi0/uZ1jJx/GA3f+FDsjixAGGzduZNmyZfzlL38hNzeXqqqq/vy6hBD7oQM6KVwxY3iH23oy9lHzRCvBYLDdhNCelvMpWF7FI48+yMpX/4ZWmj1lpTiVXzJ87IjkkLwAo0aNYsqUKcTj8S7nU9i4cSOLFy+mtraWUCjEySefjHK5efO997nnnnsgVIdZVU6m28v/rVrFOeeckxwiO50nMhJCDI4DOin0pVgsRn19PR6PJ6UB95r5/X601lSFbVa+9gZvvf06f370GQJ+PwsWXkQ0Gm1zjMfjSb42TZNwuP0iMEiMevrAAw8wefJkHn/8cf7xj38ktymvDzKzIFQH1ZVQWw0N9ehYFOVKLakJIYYWqWhOgeM41NTUJOcz7qwPwL7zKTgadtRGqWyIEQvXMywvh2EFQbZu3cyaNWsJNzrYKY4S2p76+nqGDx9OLBbjmWeeSa4/4YQTePjhh1FK4fgC1AazOf6UU/jrileo+uQjdMUeKneXDsiUiEKI/YfcKXRBa52cHDwnJ6fLnsjN8ymccuqpuNweMnPysB1NYdDN+Weexgv/9xizZ89i7NhxHHnkVOy4pq7GRmtwejA5y4033sg555xDXl4eU6dOTSak2267jR/84Ac89thjGIbBz372M2bMOJprr7ueC797PYaCKYeM5xe3/Ajt84PXDz4fyhqYieCFEOlJ5lPoQvP8vRkZGSkXGzXGbMpCcWK2Q4bHJN/v6nCICcfRhBsdohGNUolJe9wehdvt6tOJ0vel7Tg0NkK4ITG7m930Xi43+PyJh8dHYzic8nwK6Ubi6x2Jr3fSOT6ZT6GHotEo9fX1eL3eDpuEtmQ7morGOLXhOJapGJnhxu/uvCezYSj8AROPN5Ecwo0OkTD4AwrLpfttuAplWhDMgGBGoggpFk0kh3AD1NUk6h+UwtlThlNRipo8FYoOkuEzhDjADVhS+OCDD3jwwQdxHIfZs2fz1a9+tdX2VatW8cgjjyRbxsydO5fZs2cPVHht2LZNTU0NpmmSkZHR5cUwFLXZE4oRdzRZXos8v9Wt2btMUxEImsTjmnCDQ6g+jmEovD6Fy6347//+b959991Wx/R0PoV9KaUSQ2W4PZCVg3YciDQmksTOL9D/9xD6/x6CrBzUpCNh8jTUYUdAi6lGhRAHhgFJCo7j8MADD/CjH/2IvLw8br75ZmbMmEFxcXGr/Y477jgWLlw4ECF1qrkeQWtNdnZ2p/UItqPZ0xCjPmLjNg2KM914XT2vv7esxGQ92jEI1cdpCDmYYcWtP7kdyzUwA90pwwBfAHwBjCOOxlj8IHrDWli/Fv3Re/CPv6OB8lEH44w9FA6ZjDpkMipXkoQQ+7sBSQpbtmyhsLCQ4cMT/QaOO+443n333TZJIV2EQiGi0SiZmZm4XO1XvGqtqY867AnFcLQmx2eR4+ve3UFHlFK4PCbKcIhFNeHGxBzQlqXw+g0sa2CLcFROHur4OXD8HLRjw+efoTd8gLl9M/Y7r8FrL6MB8gpQEyYnkwTDR0pxkxD7mQFJCpWVleTl5SWX8/Ly2Lx5c5v93nnnHT755BNGjBjB/PnzyW+neKKkpISSkhIA7rrrrjb77N69O+UhqtvbLxwOEwqF8Pv9BIPBdi9qtqMprQ1TH4njdZmMyPTgsbo/CmpXXC4XLhf4/Jpwo01Dg019rY3bYxIImJhW/7co9ng8bf8dCobDjGOxLItYJEJ8+xZiGz4gumEd0fVr0U13EkZ2LtZhR+CedASuSUdgjRmPMvv+e+qIZVnt/g2lC4mvdyS+/pE2Fc3Tp0/n+OOPx+Vy8corr7B8+XIWLVrUZr85c+YwZ86c5PK+tfuRSKTNLGbtaa/1kW3bVFVVYVkWgUAA27bbPXZ3fZT6iE2+30WW10Sh+7yl0L7xudyQYRlEI5pI2KYqYmNZifoGy6Uwzf75RR6JRDpsQZGfn09FVRVk5cGxs+HY2SitUbu/RG9aj968gcim9UT+8ffEAT4/jDsMNWEyavwkKD4I5eu/Wd3SufUHSHy9JfH13KC3PsrNzaWioiK5XFFRkaxQbpaRkZF8PXv2bP70pz8NRGhJWuvk0NVZWVkd1iM0xmzqIjbZPots38Dm1OaKZ7dHEY1oYlFNY0NixjXTTCQIl0thmAxasY1SKjGHdGExnHQGALpyD3rzBti0Hr15Pfrp90m2g87Og5GjUCNGwYgWzxmZgxK/EEPdgFzVxo0bx65duygrKyM3N5e33nqLa6+9ttU+VVVVybF43nvvvQGvb6ivrycWi5GVldVh8ZOjNWWhOJahyO2jhHDIIYe0W5QGsGPHDubPn8/KlStbrW9ODl4f2HYiOcRizU1aE9ubE4RpDV6CaKZyh6FmngwzTwZA19XCZ5+id+6AXZ+jd32BfuMViIT3JouMLBhR3JQkRqNGFMPIUZCVO+ifR4gD2YAkBdM0+da3vsUdd9yB4ziccsopjBo1iscff5xx48YxY8YMXnrpJd577z1M0yQYDHLNNdf0+n0/XtNAbXX7RUAth852nETxj2F6sMwYEGv3mJijMf2KqTP8fVKh3BdMU2E2JQjH2ZsgIuFEfwelSCaIgWq91BWVkQlHHI064ujkOu04UFUBu3agd+1IPut3X4eG0N5k4Qs0JYvixARDeQWo/ALIHw6ZOYmWU0KIHhuw8o9p06Yxbdq0VutatrG/9NJLufTSSwcqnCStNXE7jlKq07oIR0Pc1vhMg0AnHdLuvPNORo4cyeWXXw7A0qVLMU2Tt956i5qaGuLxOD/4wQ8444wzuhVnOBzm5ptv5sMPP8Q0TRYtWsTxxx/Pxo0bueGGG4hGo2it+d3vfkdhYSHfu+Yqdu7chW3bXP3ta5k791yUAsu1N0EYHfSyHgzKMCBvGOQNQ03Z+3eitU50pGtOFjubksXHa6AmMfR3MmFYLsgrSCaK0OiDcXxBVP5wyC+AjOy0SIpCpLO0qWjuD1OmdVyJaVkWsViMqqoq4vE4ubm5HRYbaa3ZWRclEteMzva0u0+z8847j0WLFiWTwvPPP8+jjz7KwoULycjIoLKyknPPPZfTTz+9Wxeohx56CKUUr776Klu2bOGSSy7h9ddf55FHHmHhwoWcf/75RKNRbNtm5cqVFBYWJmeAq6mpwe8ziMUSdxGxaOIyqhQoQ2EoUEZi2TBUYn3TumjUwVAObs/gJBGlFGTlJDrOTTy81TYdiUDlHijfja7YDeW7obwMXVGGXrOV+tV/S+zXfIDbDXnD995dZOUmzpuZA1nZieWMLFSKrdeEOBAN6b/+VOoRAOqjNo0xh2EBF1YXF8YpU6ZQXl5OaWkpFRUVZGVlUVBQwE9+8hPeeecdlFKUlpayZ88eCgoKUo713XffZcGCBQCMHz+e4uJiPvvsM6ZPn869997Lrl27OPPMMxk7diwTJ07ktttu44477mDOnDnMnDkTSLRg0lpjxyEe1ziORmvQDtg2aEe3GTV1d2mcTR/VNh2fqOR2exRer0HRaBNfIE5WtokajITh8cCI4kRxUjvbcwN+KjZ90pQodjclj7LE82cboSExeGCbwb+CmYlElJmNyspNJIzMpsSUmd2UpHLBH5A7D3HAGbJJoaGhITl4ntfr7XA/29GUN8TxWAaZntTa2J9zzjm88MILlJWVcd555/H0009TUVHBSy+9hMvlYubMmUQikT75HF/72teYOnUqr776KvPmzePuu+/mhBNO4OWXX2blypUsXryYE044geuvvx5I/PK2XIlipPZovTdROFqTZ5t8ZZqbSEQTjSQG7otENDXVNru+SLQoc7kUucNM8gss8gpcZGYbaXGxNHx+VNEYKBrTbtLQsViiaKq2Cmqq0DWJZ2qr0DWJ9Xrz+sS6eKKeqVUCsaxksiArF9V8t5HVnExyEtszs+XuQ+w3huRfajwep7q6GpfLRTAY7HTfioYYtqMZmeFO+UJ33nnnceONN1JZWclTTz3F888/T35+Pi6XizfffJMvvvii2zEfffTRPPPMM5xwwgls3bqVL7/8knHjxvGvf/2LMWPGsHDhQr788ks++eQTxo8fT3Z2NhdccAGZmZn87//+b8rvo1Si+AgDTBKD9eUPa7/IzO/LZtOnZVSUxSkvi7N7ZxgI43Ir8gqsRJIYZpGRlR5JYl/K5UrWYwDtJg5oqtdoDEFzomhOHk0PXVsFe3aht2yA+sRdVYd3Hy2SR6hwBI4yUcHMRGurYGbi4fWl5fclhoYhmRRs28Y0TbKysjr9z9cYs6mN2GR7LTzd6D186KGHEgqFkkN7nH/++cyfP5/Zs2dz+OGHM378+G7HPH/+fG6++WZmz56NaZr84he/wOPx8Pzzz/PUU09hWRYFBQV873vfY926ddx+++2J4TJcLn72s591+/1S4Q9YFI9xUzwmMYtbY4ND+e54U5KIUfpFn6vs+AAAFqJJREFU4te129MiSRRYBDMGP0lonfoItEop8AcTjw6KqpLnjTfdfdRUQ01lImFUV7VKJrr0C6itor6pc2KbBGJaieSQkUgSqjlZND8yMlHBjEQ8vkDTUOeBRJITopeG7HwKpml22GMZEkUnX9REcXSicnmgm6D2ZA7p/tDZ99lVj82GkN0iScQJNyb+1DxeRd4wi2CmgT9g4AuY+AMGXl/fVmbn5eWx4/M91NfZhGod6uts6usSz+FGTXaOSWGRi8IiF8HMgU1UWmvyAn4q/rUtcXdRV4Our028rq+F+jp0XU2L5VoI1UNn/10tVyJB+IN758TwBRK9xn0B8Adarwskhk4nkHjsm1TSuUcuSHy9Meg9mtNRVxeA6rBN1HYYkeFOmz4J+xt/wGT0WJPRYz1orWmodygvSySJivI4O3e0vsApBV5/IlE0P3x+A38w8drrVe1WaMdimlDt3gt+fZ1DqNYmFKrBju99D8uCQIZJ3jALj9egoizOpx+F+fSjMP6gQeHIRILIyTf7vaWVUgrDH0ANK4RhhYl1XRyjHTuRGOproa4WGkPoxlBiiPOGUKKIqzExaVJyfXXl3teRvXN928rE0Pv8KPJ4WyWK6tx8HJc7mTQIZCTuUJqXvb7EMW7PgI5pJfrXkE0KnYnaDlWNcQJus9M+CX3lk08+adPD2+Px8Ne//rXf33ugKKUIZJgEMkzGjEvUUdh2Yu6IhtDeR2PT857SWPLOInkOg0SSCBh4vIpwg0N9nUMk3GI/Bf6AQTDDYNRBAQwrSjDTIJhh4vG27bzX2OCwe2eM0i9jbN8S4bNNEVxuxfCRFoVFLoYVugZ8VNqOKMNM1D1kZMGIpnXdOL6uOsbuzxvYvdOmskaR4YkxMlDFCPUlgUg51NdBqA4dSjzHt21G11Y33aEkhlPp8D7FssDtTSQJj6fpddMcHR4vqnnZ4927rem16mB98rXlGvTixqFkyBYfdVQ8o7VmV12MxrjDmCw3ljk4PWQPhOKj3rLtxNhOLZNF8+two4PXZxDMNAlkJJJAMMPEHzSSgwN2N754TFNWmkgQZbvixKIaw4D84YkEMXykC6+v7/4e+vv7cxxNVYXN7i9jlO6MEapLXNgzs03yh1tUV8SpLE/cLWTnmvz/9s48Nory/+Pv2Z3dbbsL2xNKawmHBS1XxTYQbmklRholBDAYJCIGTVEEAuFIPAuCAlakoA2pCEQDYkAUIyJHaQT8Ai3l0lopUPlRSo/tsT22u7Pz/P6Y3elud3vRPUr5vJLNHM8znc88nZn3PJ+Z5/OJ7q9CVH+1fIx2+5goSj0Nm1igziYcpkbA3ASYTUBTk9QTsc2zJpNU1mSyrW9qnpo7+eUdp3AQC9tUEwBVYBAsjEluM54Hp5Sm4HnpvYxKJU3ty9Jnd811VGpwLf5my/muiBG5j3oIdWYRDRYrwrUqvwkCIaFUctD1UkLXyzeuCV7FISpGjagYNUSRwVAuoPSuBaUlAsruNQJoREiYEn2jJIGQBMj/saUcsQvb/bsW3LcJG6cAwvvwGBSrQd9oFQKDms/rhnoRJXfMuFtswfV8E67nmxDWh0d0fxV0OkkwOIUC0Oqkn62L0pUjZqIopX9tKRi2X5uC4lhutUrCJFgAQZDyjtvmIQiwDchpzj/uzpb2jFW7ipE8z6skt5mSB9xM63r1gthkltbxjmW8LFacWiMNIFKrpak8r5GmvBpQqXwavoV6Cg5YRYb/aprAKzg81rvjn6B6A+opdB1P2ccYg7FGlATirgU1Vc2+eIXCFlvK9lPb4kxJywppuWW57denT4RH7GtsEOXeQGWZAFGUbOrbj0dfmwtM1cq4FEfqaq24+58Fd/8zo94oglMAEX15RPdXIzJa1erYFn/R0f8vY8wmDg6CIVhsImPv6ZikEfJmuzi5zrOW6wVBEiZry6ltXrQCouiZg+VVzsKhUoObNA2K5Bcf6M9RT6GDVDYInR6TQPR8OI5D72AlegcrMWRYgPzpbZNJyoxnNtsCEZoZGhsYas1WWCzMPt6tVZTKWtsDo21AIW/LjcFz0jwv9V7s65unADgOlWUWlN4V5KCPWp0CA2I1iIx6sJflut5KDB2uxJBhGtRWW2Eo53HjnxqU/a8BCiUQGaVCVH8V+vRTtZu/gzEGQQAsZgbBFl5FsDQHbBQskmtOPlbbcTku29umqy/9OY6TXEntfLLr6Ss+PDwc5WVlNpGwNIuFYJ9apB6T2dw8FcxgZjNgabKttzjMN/+Y2QxovRNenkTBRqNFRG2T0OkxCcSjR2CQAjED1e3WE8XmWFOyeDQ1r1PxATAaGyBYGARBuok2mRgEQYRVYLb1be8jNFyJJ0cFIDJKBV1vz7jZOI6DPoTH4NhwDIhlMFRYUfKfGSV3LCi5YwGvkgRCpebkm7zjTV+wSF+EeYpm8ZBEQmkTjSCtBUy0yCP07YEe7dOW87wfwshzCoWtO9nxMST+fhwlUYD0VFNeb/FonoSO0lY+BeLhRqHgoNFw0LQSQ7Ej7g/HWFWCg1CIVgZ9iBKaAO8+wHCcNKYkLILHsKcYKsoElBRLrirY3vHas/8FBinQW9+cDVC+SdtdaioOvEMYdyY6H5fjcVptIikIDFZZNB3qWBhqqy0wmSxSm7TTK7MjCwjPgVMAYC3eKzCnieuyw4JawyHQ9tl080/Ko65W+/vW/uD0aFHIyclBeXm52zLHfAqCyGCxMqiVHHLb6apGRERg0qRJHreVINzRXqwqX6JQcOgTqUKfSA+NnFZ27bgcRdUunnKPxTZ1cl3J6wCL0Bz8kXN8NudaPKm7WZZ2CJibGGoMVpT+n8Xl1YFCCeh6NUCtYbJY2IUjwDblOFswSpHZXj8wiCKc59so0wcrERrh+Vt4jxaFjsCYJAhKBaD0wIAlT+ZTqK+vx4IFC9xud+DAAWRmZgIAnnzySWzbtg3l5eVYvXo1iouLAQAbNmxAYmJil4+JILo7/hRPxhjMTdLn09JPmhcFFWqqG92OufEEg5/QkCh0lrae6O35FOxjEvrr1VB54BNUT+ZT0Gg0yMrKctmusLAQW7duxU8//YTQ0FBUVUnJZt59912MHTsWWVlZsFqtqK+v7/LxEATRNhzHQRPAQROgQLBD6nnHnoxoZTCZbIJRL6KxUQSY9LpBoZDyqjdPbfMKQKG0TZ3mpam3BlX2aFFoD3lMQpDKI4IAeDafAmMMGzdudNnuzJkzSElJQWiodAbac1ufOXMGW7duBSDFdurd2ztfJxAE0TkUSinicJAWQIS/rWmbR1YUpDwJFmh4BfQBnh0c5al8Ct7Mw0AQBOGOR/bby/K6JlhFhgit5+OqvPDCCzh8+DB++eUXpKSkwGg0PlA+hda2Gz9+PI4cOQKDwQAAsvtowoQJ2LNnDwApPHhtba1Hj4sgiJ7PIykKJouI6kYL9AE8ArwwJsFdPoXLly8jKSkJP/zwQ4fzKbS23dChQ7FkyRLMmjULycnJ+PDDDwEAH330Ec6ePYukpCQ899xzKCws9PixEQTRs/FZmIv8/Hzs2rULoigiKSkJM2bMcCq3WCzIyMjAzZs30atXLyxdurRDOYwfJMyFSRBR1WhFHy3vkS+OvAGFueg6ZF/XIPu6Rne2r60wFz7pKYiiiKysLKxduxbp6eluXSgnT56EVqvFtm3bMH36dHz77bdesyeAVyAmJLDbCgJBEIS/8MmL5hs3bsiuFAAYN24cLly4gMcee0yuc/HiRcyePRsAMHbsWHz99dedSpn4MPMo5FMgCOLhwCeiYDAYEBYWJi+HhYW5hHZwrKNUKhEUFASj0ejyWeXx48dx/PhxAMDGjRsRHh7uVH7//n3wfMcOq6P1vM2IESNw6tQpf5vhFo1G49LGdnieb7WsO0D2dQ2yr2t0d/tao3vcFTtBcnIykpOT5eWWPjuz2QzGWLs3/O7is2+N7mCfIAiwWCyt+kW7s88UIPu6CtnXNbqzfX4PnR0aGorKykp5ubKyUh541bJOWFgYrFYrGhoa0KtXr07vKyAgACaTCU1NTW26njQaTbf+5t/f9jHGoFAoEBAQ4DcbCILwPT4RhcGDB+PevXsoKytDaGgozp496+JDf/rpp5GdnY0hQ4bgzz//xLBhwx7ofQLHcQgMDGy3XndWcaD720cQRM/EJ6KgVCrx2muvYf369RBFEc888wxiYmKwf/9+DB48GAkJCZg6dSoyMjLw9ttvQ6fTYenSpb4wjSAIgnDAZ+8URo8ejdGjRzute+mll+R5tVqN5cuX+8ocgiAIwg2P5IhmgiAIwj0+G9FMEARBdH8e2Z7C6tWr/W1Cm3R3+4DubyPZ1zXIvq7R3e1rjUdWFAiCIAhXSBQIgiAIGeUHH3zwgb+N8BeDBg3ytwlt0t3tA7q/jWRf1yD7ukZ3t88d9KKZIAiCkCH3EUEQBCFDokAQBEHIPHRRUjuLtzK+eYKKigps374d1dXV4DgOycnJeP75553qXL9+HZ9++qls05gxYzBr1iyf2AcAixcvRkBAABQKBZRKJTZu3OhUzhjDrl27cOnSJWg0GqSmpvrMj1pSUoL09HR5uaysDHPmzMH06dPldf5ovx07diAvLw96vR5btmwBANTV1SE9PR3l5eWIiIjAsmXLoNPpXLbNzs7GwYMHAUjpWKdMmeIT+/bu3Yvc3FzwPI++ffsiNTUVWq3WZdv2zgdv2ff999/jxIkTcij9uXPnukRIANq/3r1lX3p6upwF0p6tcNOmTS7b+qL9ugzrwVitVvbWW2+x0tJSZrFY2IoVK9idO3ec6hw9epRlZmYyxhj7448/2GeffeYz+wwGAysqKmKMMdbQ0MCWLFniYt+1a9fYhg0bfGZTS1JTU1lNTU2r5bm5uWz9+vVMFEX2zz//sDVr1vjQumasVit7/fXXWVlZmdN6f7Tf9evXWVFREVu+fLm8bu/evezQoUOMMcYOHTrE9u7d67Kd0WhkixcvZkaj0WneF/bl5+czQRBkW93Zx1j754O37Nu/fz87fPhwm9t15Hr3ln2O7N69mx04cMBtmS/ar6v0aPeRY8Y3nufljG+OXLx4UX4aGzt2LK5duwbmo3fvISEh8lN1YGAgoqOjYTAYfLJvT3Hx4kVMmjQJHMdhyJAhqK+vR1VVlc/tuHr1KiIjIxEREeHzfbckLi7OpRdw4cIFTJ48GQAwefJkl/MQkJ5yR44cCZ1OB51Oh5EjRyI/P98n9o0aNQpKpRIAMGTIEL+eh+7s6wgdud69bR9jDOfOncP48eM9vl9f0aPdR57M+OZtysrKcOvWLTz++OMuZYWFhVi5ciVCQkLwyiuvICYmxqe2rV+/HgDw7LPPOiU4AqT2c8wuFRYWBoPBgJCQEJ/aeObMmVYvRH+3HwDU1NTIbRIcHIyamhqXOi3P19DQUL/cnE+ePIlx48a1Wt7W+eBNfvvtN+Tk5GDQoEGYP3++y425I9e7t/n777+h1+vRr1+/Vuv4q/06So8WhYcFk8mELVu24NVXX0VQUJBT2cCBA7Fjxw4EBAQgLy8PmzZtwhdffOEz29LS0hAaGoqamhqsW7cOUVFRiIuL89n+O4IgCMjNzcXLL7/sUubv9nMHx3HdNvf4wYMHoVQqMXHiRLfl/jofpk2bJr8L2r9/P/bs2YPU1FSv77eztPVwAjwc11OPdh91JuMbgC5lfHtQBEHAli1bMHHiRIwZM8alPCgoSM5+Nnr0aFitVtTW1vrMPnt76fV6JCYm4saNGy7ljsmA3LWxt7l06RIGDhyI4OBglzJ/t58dvV4vu9Wqqqrc9kRbnq8Gg8GnbZmdnY3c3FwsWbKkVdFq73zwFsHBwVAoFFAoFEhKSkJRUZFb29q73r2J1WrF+fPn2+xl+av9OkOPFgXHjG+CIODs2bNISEhwqmPP+AagSxnfHgTGGL766itER0cjJSXFbZ3q6mr5HceNGzcgiqLPRMtkMqGxsVGev3LlCvr37+9UJyEhATk5OWCMobCwEEFBQd3KdeTP9nMkISEBp0+fBgCcPn0aiYmJLnXi4+Nx+fJl1NXVoa6uDpcvX0Z8fLxP7MvPz8fhw4exatUqaDQat3U6cj54C8f3VOfPn3frAuzI9e5Nrl69iqioKCcXliP+bL/O0ONHNOfl5WH37t1yxreZM2c6ZXwzm83IyMjArVu35Ixvffv29YltBQUFeO+999C/f39ZiObOnSs/eU+bNg1Hjx7FsWPHoFQqoVarMX/+fAwdOtQn9t2/fx+bN28GID0FTZgwATNnzsSxY8dk+xhjyMrKwuXLl6FWq5GamorBgwf7xD5AurhSU1ORkZEhu94c7fNH+33++ef466+/YDQaodfrMWfOHCQmJiI9PR0VFRVOn6QWFRXh999/x5tvvglA8ucfOnQIgPRJ6jPPPOMT+w4dOgRBEGQ/fWxsLBYtWgSDwYDMzEysWbOm1fPBF/Zdv34dt2/fBsdxiIiIwKJFixASEuJkH+D+eveFfVOnTsX27dsRGxuLadOmyXX90X5dpceLAkEQBNFxerT7iCAIgugcJAoEQRCEDIkCQRAEIUOiQBAEQciQKBAEQRAyJAoE4QfmzJmD0tJSf5tBEC5QmAuCgBTSuLq6GgpF83PSlClTsHDhQj9aRRC+h0SBIGysWrUKI0eO9LcZBOFXSBQIog2ys7Nx4sQJDBgwADk5OQgJCcHChQsxYsQIANKI1Z07d6KgoAA6nQ4vvviiHPlSFEX8+OOPOHXqFGpqatCvXz+sXLlSjip75coVfPzxx6itrcWECROwcOFCcByH0tJSfPnll7h9+zZ4nsfw4cOxbNkyv7UB8WhBokAQ7fDvv/9izJgxyMrKwvnz57F582Zs374dOp0OW7duRUxMDDIzM1FSUoK0tDRERkZi+PDhOHLkCM6cOYM1a9agX79+KC4udoorlJeXhw0bNqCxsRGrVq1CQkIC4uPjsW/fPowaNQrvv/8+BEHAzZs3/Xj0xKMGiQJB2Ni0aZOcaAYA5s2bB57nodfrMX36dHAch3HjxuHnn39GXl4e4uLiUFBQgNWrV0OtVmPAgAFISkrC6dOnMXz4cJw4cQLz5s1DVFQUAGDAgAFO+5sxYwa0Wi20Wi2GDRuG27dvIz4+HjzPo7y8HFVVVQgLC8MTTzzhy2YgHnFIFAjCxsqVK13eKWRnZyM0NNQpcm5ERAQMBgOqqqqg0+kQGBgol4WHh8thnSsrK9sMrugY6luj0cBkMgGQxGjfvn1Yu3YttFotUlJSMHXqVI8cI0G0B4kCQbSDwWAAY0wWhoqKCiQkJCAkJAR1dXVobGyUhaGiokKOmR8WFob79+93OjxycHCwHDW1oKAAaWlpiIuLQ2RkpAePiiDcQ+MUCKIdampq8Ouvv0IQBJw7dw53797FU089hfDwcAwdOhTfffcdzGYziouLcerUKTlrWVJSEvbv34979+6BMYbi4mIYjcZ293fu3Dk5WYxWqwWAbpupjeh5UE+BIGx88sknTuMURo4cicTERMTGxuLevXtYuHAhgoODsXz5cjlRzzvvvIOdO3fijTfegE6nw+zZs2UXVEpKCiwWC9atWwej0Yjo6GisWLGiXTuKiorwzTffoKGhAcHBwViwYIHPcnwQBOVTIIg2sH+SmpaW5m9TCMInkPuIIAiCkCFRIAiCIGTIfUQQBEHIUE+BIAiCkCFRIAiCIGRIFAiCIAgZEgWCIAhChkSBIAiCkPl/nF/MyNPLV+YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL-mh9vLNTso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52b4f871-105e-4179-a896-0bc171ff26e1"
      },
      "source": [
        "correct = 0\n",
        "false=0\n",
        "for idx,test in enumerate(test_input_letter):\n",
        "  test = np.expand_dims(test, 0)\n",
        "  model_letter.load_weights(\"model_letter.h5\")\n",
        "  predictions = model_letter.predict(test)[0]\n",
        "  label = np.argmax(predictions)\n",
        "  if (label == test_target_letter[idx]): \n",
        "    correct += 1\n",
        "test_accuracy = correct/len(test_target_letter)\n",
        "print(\"test_accuracy_letter:\" , test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_accuracy_letter: 0.9138088012139606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6XBvgnOlK7K",
        "colab_type": "text"
      },
      "source": [
        "# Resualts\n",
        "\n",
        "**⚠**  Because of the shortage of the dataset size, neural networks couldn't have been trained well and final results are not as good as we expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1mLBAcYtSJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model,model_type, imgPath):\n",
        "  image = load_img(imgPath, target_size=(28, 28), grayscale=True)\n",
        "  image = img_to_array(image) / 255.\n",
        "  orig_img = image.copy()\n",
        "  image = np.expand_dims(image, 0)\n",
        "  model.load_weights(model_type)\n",
        "  predictions = model.predict(image)[0]\n",
        "  label = np.argmax(predictions)\n",
        "  return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFgRL3_sJcvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(code):\n",
        "  codes={ 0:'ا',1:'ب',2:'پ',3:'ت',4:'ث',5:'ج',6:'چ',7:'ح',8:'خ',9:'د',10:'ذ',11:'ر',\n",
        "       12:'ز',13:'ژ',14:'س',15:'ش',16:'ص',17:'ض',18:'ط',19:'ظ',20:'ع',21:'غ',22:'ف',23:'ق',\n",
        "       24:'ک',25:'گ',26:'ل',27:'م',28:'ن',29:'و',30:'ه',31:'ی'}\n",
        "  plain = codes[code]\n",
        "  return plain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9nrQ6hSS0bP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76dc148c-f876-4436-b001-eca37ab497c2"
      },
      "source": [
        "from keras.layers import Input\n",
        "input = Input((28, 28, 1))\n",
        "model_digit = build_model(input)\n",
        "model_letter = build_model_letter(input)\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "model_type = None\n",
        "detected_ID = ''\n",
        "detected_FN = ''\n",
        "detected_LN = ''\n",
        "test_forms = glob.glob(\"extracted_form_test/*\")\n",
        "test_forms.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "for test_dir in test_forms:\n",
        "  form_id = test_dir.split(os.path.sep)[-1]\n",
        "  imgPaths = glob.glob(test_dir + \"/*.png\")\n",
        "  imgPaths.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "  for imgPath in tqdm(imgPaths):\n",
        "    image = load_img(imgPath, target_size=(28, 28), grayscale=True)\n",
        "    image = img_to_array(image) / 255.\n",
        "    orig_img = image.copy()\n",
        "    image = np.expand_dims(image, 0)\n",
        "    if(imgPath.find('ID') != -1):\n",
        "      model_type = 'model_digit.h5'\n",
        "      detected_ID += str(predict(model_digit,model_type,imgPath))\n",
        "    if(imgPath.find('FN') != -1):\n",
        "      model_type = 'model_letter.h5'\n",
        "      detected_FN += decode(predict(model_letter,model_type,imgPath))\n",
        "    if(imgPath.find('LN')!=-1):\n",
        "      model_type = 'model_letter.h5'\n",
        "      detected_LN += decode(predict(model_letter,model_type,imgPath))\n",
        "  ID[form_id] = detected_ID\n",
        "  detected_ID = ''\n",
        "  Firstname[form_id] = detected_FN[::-1]\n",
        "  detected_FN = ''\n",
        "  Lastname[form_id] = detected_LN[::-1]\n",
        "  detected_LN = ''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/22 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"LeNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               1225500   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 1,256,080\n",
            "Trainable params: 1,256,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"LeNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500)               1225500   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                16032     \n",
            "=================================================================\n",
            "Total params: 1,267,102\n",
            "Trainable params: 1,267,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n",
            "100%|██████████| 22/22 [00:26<00:00,  1.22s/it]\n",
            "100%|██████████| 27/27 [00:18<00:00,  1.45it/s]\n",
            "100%|██████████| 21/21 [00:13<00:00,  1.52it/s]\n",
            "100%|██████████| 22/22 [00:13<00:00,  1.58it/s]\n",
            "100%|██████████| 28/28 [00:17<00:00,  1.58it/s]\n",
            "100%|██████████| 24/24 [00:15<00:00,  1.56it/s]\n",
            "100%|██████████| 23/23 [00:14<00:00,  1.63it/s]\n",
            "100%|██████████| 26/26 [00:15<00:00,  1.69it/s]\n",
            "100%|██████████| 23/23 [00:13<00:00,  1.68it/s]\n",
            "100%|██████████| 21/21 [00:12<00:00,  1.70it/s]\n",
            "100%|██████████| 26/26 [00:16<00:00,  1.56it/s]\n",
            "100%|██████████| 23/23 [00:12<00:00,  1.77it/s]\n",
            "100%|██████████| 24/24 [00:14<00:00,  1.68it/s]\n",
            "100%|██████████| 24/24 [00:14<00:00,  1.62it/s]\n",
            "100%|██████████| 23/23 [00:13<00:00,  1.65it/s]\n",
            "100%|██████████| 21/21 [00:11<00:00,  1.80it/s]\n",
            "100%|██████████| 25/25 [00:15<00:00,  1.62it/s]\n",
            "100%|██████████| 26/26 [00:17<00:00,  1.48it/s]\n",
            "100%|██████████| 24/24 [00:15<00:00,  1.59it/s]\n",
            "100%|██████████| 23/23 [00:13<00:00,  1.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEe1_3LaWfYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4f5b251-a76a-41fa-cc6a-34f6f0075a3d"
      },
      "source": [
        "for key,value in Lastname.items():\n",
        "  print(\"-------------------------------------\")\n",
        "  print(\"Image:\", key)\n",
        "  print(\"ID\",ID[key])\n",
        "  print(\"Firstname\",Firstname[key])\n",
        "  print(\"Lastname\",Lastname[key])\n",
        "  print(\"Degree\", Degree[key])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "Image: 1\n",
            "ID 9657213\n",
            "Firstname نظا\n",
            "Lastname سلطانی\n",
            "Degree PHD\n",
            "-------------------------------------\n",
            "Image: 2\n",
            "ID 0977901\n",
            "Firstname معموتاقر\n",
            "Lastname سالاری\n",
            "Degree BS\n",
            "-------------------------------------\n",
            "Image: 3\n",
            "ID 98756232\n",
            "Firstname شفق\n",
            "Lastname اسدی\n",
            "Degree PHD\n",
            "-------------------------------------\n",
            "Image: 4\n",
            "ID 94444121\n",
            "Firstname نیلا\n",
            "Lastname امین\n",
            "Degree PHD\n",
            "-------------------------------------\n",
            "Image: 5\n",
            "ID 9527502\n",
            "Firstname امیوعلی\n",
            "Lastname حسینزاده\n",
            "Degree BS\n",
            "-------------------------------------\n",
            "Image: 6\n",
            "ID 9323993\n",
            "Firstname طاها\n",
            "Lastname سماواتی\n",
            "Degree BS\n",
            "-------------------------------------\n",
            "Image: 7\n",
            "ID 98731243\n",
            "Firstname فرزاد\n",
            "Lastname صبحی\n",
            "Degree MS\n",
            "-------------------------------------\n",
            "Image: 8\n",
            "ID 95012121\n",
            "Firstname رزیتا\n",
            "Lastname عظیمیان\n",
            "Degree MS\n",
            "-------------------------------------\n",
            "Image: 9\n",
            "ID 99337567\n",
            "Firstname سهبد\n",
            "Lastname تابعی\n",
            "Degree BS\n",
            "-------------------------------------\n",
            "Image: 10\n",
            "ID 9312567\n",
            "Firstname سیما\n",
            "Lastname نظری\n",
            "Degree BS\n",
            "-------------------------------------\n",
            "Image: 11\n",
            "ID 98444114\n",
            "Firstname فزناز\n",
            "Lastname عسننژطد\n",
            "Degree BS\n",
            "-------------------------------------\n",
            "Image: 12\n",
            "ID 11342135\n",
            "Firstname زهراه\n",
            "Lastname بیگی\n",
            "Degree MS\n",
            "-------------------------------------\n",
            "Image: 13\n",
            "ID 92345667\n",
            "Firstname پیتا\n",
            "Lastname بابایی\n",
            "Degree MS\n",
            "-------------------------------------\n",
            "Image: 14\n",
            "ID 9386137\n",
            "Firstname ستایش\n",
            "Lastname ثرهادی\n",
            "Degree PHD\n",
            "-------------------------------------\n",
            "Image: 15\n",
            "ID 9152832\n",
            "Firstname علی\n",
            "Lastname بیراوند\n",
            "Degree MS\n",
            "-------------------------------------\n",
            "Image: 16\n",
            "ID 8252190\n",
            "Firstname اصغر\n",
            "Lastname مثدم\n",
            "Degree PHD\n",
            "-------------------------------------\n",
            "Image: 17\n",
            "ID 9513367\n",
            "Firstname شاهین\n",
            "Lastname کامبیزی\n",
            "Degree PHD\n",
            "-------------------------------------\n",
            "Image: 18\n",
            "ID 93774415\n",
            "Firstname برویذ\n",
            "Lastname اجمدیان\n",
            "Degree MS\n",
            "-------------------------------------\n",
            "Image: 19\n",
            "ID 9731203\n",
            "Firstname سووقا\n",
            "Lastname انصاوی\n",
            "Degree BS\n",
            "-------------------------------------\n",
            "Image: 20\n",
            "ID 96624751\n",
            "Firstname زینب\n",
            "Lastname صتاوی\n",
            "Degree BS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qxVc_4Kzq0c",
        "colab_type": "text"
      },
      "source": [
        "###**Final Resaults**\n",
        "\n",
        "Reading and extracting ID, Firstname, Lastname, and Degree of 20 test forms and computing the time of this process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un_VJ3_Cvfke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04e46839-bf96-4f13-e4f1-878b9e809fd2"
      },
      "source": [
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "\n",
        "form_test_dir = glob.glob(\"form_test/*\")\n",
        "\n",
        "\n",
        "for test_dir in tqdm(form_test_dir):\n",
        "    dir = test_dir.split(os.path.sep)[-1]\n",
        "    folder_name = dir[:-4]\n",
        "    Degree[folder_name] = extracted_form_test(test_dir)\n",
        "\n",
        "input = Input((28, 28, 1))\n",
        "model_digit = build_model(input)\n",
        "model_letter = build_model_letter(input)\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "model_type = None\n",
        "detected_ID = ''\n",
        "detected_FN = ''\n",
        "detected_LN = ''\n",
        "test_forms = glob.glob(\"extracted_form_test/*\")\n",
        "test_forms.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "for test_dir in test_forms:\n",
        "  form_id = test_dir.split(os.path.sep)[-1]\n",
        "  imgPaths = glob.glob(test_dir + \"/*.png\")\n",
        "  imgPaths.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
        "  for imgPath in tqdm(imgPaths):\n",
        "    image = load_img(imgPath, target_size=(28, 28), grayscale=True)\n",
        "    image = img_to_array(image) / 255.\n",
        "    orig_img = image.copy()\n",
        "    image = np.expand_dims(image, 0)\n",
        "    if(imgPath.find('ID') != -1):\n",
        "      model_type = 'model_digit.h5'\n",
        "      detected_ID += str(predict(model_digit,model_type,imgPath))\n",
        "    if(imgPath.find('FN') != -1):\n",
        "      model_type = 'model_letter.h5'\n",
        "      detected_FN += decode(predict(model_letter,model_type,imgPath))\n",
        "    if(imgPath.find('LN')!=-1):\n",
        "      model_type = 'model_letter.h5'\n",
        "      detected_LN += decode(predict(model_letter,model_type,imgPath))\n",
        "  ID[form_id] = detected_ID\n",
        "  detected_ID = ''\n",
        "  Firstname[form_id] = detected_FN[::-1]\n",
        "  detected_FN = ''\n",
        "  Lastname[form_id] = detected_LN[::-1]\n",
        "  detected_LN = ''\n",
        "\n",
        "for key,value in Lastname.items():\n",
        "  print(\"-------------------------------------\")\n",
        "  print(\"Form:\", key)\n",
        "  print(\"ID\",ID[key])\n",
        "  print(\"Firstname\",Firstname[key])\n",
        "  print(\"Lastname\",Lastname[key])\n",
        "  print(\"degree:\",Degree[key])\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "print('Time: ', stop - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  5%|▌         | 1/20 [00:00<00:05,  3.37it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 10%|█         | 2/20 [00:00<00:05,  3.48it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 15%|█▌        | 3/20 [00:00<00:04,  3.77it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 20%|██        | 4/20 [00:00<00:04,  4.00it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 25%|██▌       | 5/20 [00:01<00:03,  3.83it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 30%|███       | 6/20 [00:01<00:03,  3.67it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 35%|███▌      | 7/20 [00:01<00:03,  3.72it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 40%|████      | 8/20 [00:02<00:03,  3.70it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 45%|████▌     | 9/20 [00:02<00:02,  3.78it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 50%|█████     | 10/20 [00:02<00:02,  3.82it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 55%|█████▌    | 11/20 [00:02<00:02,  3.72it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 60%|██████    | 12/20 [00:03<00:02,  3.99it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 65%|██████▌   | 13/20 [00:03<00:01,  3.91it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 70%|███████   | 14/20 [00:03<00:01,  3.88it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 75%|███████▌  | 15/20 [00:03<00:01,  3.93it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 80%|████████  | 16/20 [00:04<00:00,  4.02it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 85%|████████▌ | 17/20 [00:04<00:00,  3.87it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 90%|█████████ | 18/20 [00:04<00:00,  3.73it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 95%|█████████▌| 19/20 [00:04<00:00,  3.75it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 20/20 [00:05<00:00,  3.79it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"LeNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_39 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_147 (Conv2D)          (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_147 (MaxPoolin (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_148 (Conv2D)          (None, 14, 14, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_148 (MaxPoolin (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_74 (Flatten)         (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 500)               1225500   \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 1,256,080\n",
            "Trainable params: 1,256,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"LeNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_39 (InputLayer)        (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_149 (Conv2D)          (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_149 (MaxPoolin (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_150 (Conv2D)          (None, 14, 14, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_150 (MaxPoolin (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_75 (Flatten)         (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 500)               1225500   \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 32)                16032     \n",
            "=================================================================\n",
            "Total params: 1,267,102\n",
            "Trainable params: 1,267,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 5/19 [00:00<00:00, 37.55it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 53%|█████▎    | 10/19 [00:00<00:00, 39.20it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 19/19 [00:00<00:00, 41.49it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/24 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 33%|███▎      | 8/24 [00:00<00:00, 73.06it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 54%|█████▍    | 13/24 [00:00<00:00, 53.01it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 71%|███████   | 17/24 [00:00<00:00, 45.51it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 24/24 [00:00<00:00, 42.52it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 44%|████▍     | 8/18 [00:00<00:00, 68.11it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 72%|███████▏  | 13/18 [00:00<00:00, 58.53it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 18/18 [00:00<00:00, 50.97it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 42%|████▏     | 8/19 [00:00<00:00, 72.10it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 68%|██████▊   | 13/19 [00:00<00:00, 60.01it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 19/19 [00:00<00:00, 49.77it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 32%|███▏      | 8/25 [00:00<00:00, 72.74it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 48%|████▊     | 12/25 [00:00<00:00, 55.65it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 68%|██████▊   | 17/25 [00:00<00:00, 51.05it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 25/25 [00:00<00:00, 48.02it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 38%|███▊      | 8/21 [00:00<00:00, 75.29it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 62%|██████▏   | 13/21 [00:00<00:00, 61.75it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 81%|████████  | 17/21 [00:00<00:00, 50.93it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 47.60it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 40%|████      | 8/20 [00:00<00:00, 65.58it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 57.19it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 50.20it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 35%|███▍      | 8/23 [00:00<00:00, 75.01it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 57%|█████▋    | 13/23 [00:00<00:00, 61.80it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 74%|███████▍  | 17/23 [00:00<00:00, 53.03it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 49.01it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 35%|███▌      | 7/20 [00:00<00:00, 62.98it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 55%|█████▌    | 11/20 [00:00<00:00, 52.47it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 75%|███████▌  | 15/20 [00:00<00:00, 46.65it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 44.93it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 39%|███▉      | 7/18 [00:00<00:00, 66.58it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 67%|██████▋   | 12/18 [00:00<00:00, 58.00it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 18/18 [00:00<00:00, 51.05it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 35%|███▍      | 8/23 [00:00<00:00, 71.79it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 52%|█████▏    | 12/23 [00:00<00:00, 53.66it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 70%|██████▉   | 16/23 [00:00<00:00, 47.87it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 45.59it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 40%|████      | 8/20 [00:00<00:00, 71.14it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 59.97it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 51.10it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 38%|███▊      | 8/21 [00:00<00:00, 75.51it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 62%|██████▏   | 13/21 [00:00<00:00, 62.07it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 51.30it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 38%|███▊      | 8/21 [00:00<00:00, 69.34it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 62%|██████▏   | 13/21 [00:00<00:00, 58.12it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 49.82it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 40%|████      | 8/20 [00:00<00:00, 69.15it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 60%|██████    | 12/20 [00:00<00:00, 54.08it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 80%|████████  | 16/20 [00:00<00:00, 47.10it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 44.31it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 39%|███▉      | 7/18 [00:00<00:00, 68.87it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 67%|██████▋   | 12/18 [00:00<00:00, 58.95it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 18/18 [00:00<00:00, 49.96it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 36%|███▋      | 8/22 [00:00<00:00, 67.62it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 59%|█████▉    | 13/22 [00:00<00:00, 57.25it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 22/22 [00:00<00:00, 48.99it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 35%|███▍      | 8/23 [00:00<00:00, 69.45it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 57%|█████▋    | 13/23 [00:00<00:00, 59.64it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 78%|███████▊  | 18/23 [00:00<00:00, 52.58it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 23/23 [00:00<00:00, 49.13it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 38%|███▊      | 8/21 [00:00<00:00, 73.39it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 62%|██████▏   | 13/21 [00:00<00:00, 62.46it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 21/21 [00:00<00:00, 52.31it/s]\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 40%|████      | 8/20 [00:00<00:00, 77.11it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 65%|██████▌   | 13/20 [00:00<00:00, 62.19it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 20/20 [00:00<00:00, 52.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "Form: 1\n",
            "ID 9657213\n",
            "Firstname نظا\n",
            "Lastname سلطانی\n",
            "degree: PHD\n",
            "-------------------------------------\n",
            "Form: 2\n",
            "ID 0977901\n",
            "Firstname معموتاقر\n",
            "Lastname سالاری\n",
            "degree: BS\n",
            "-------------------------------------\n",
            "Form: 3\n",
            "ID 98756232\n",
            "Firstname شفق\n",
            "Lastname اسدی\n",
            "degree: PHD\n",
            "-------------------------------------\n",
            "Form: 4\n",
            "ID 94444121\n",
            "Firstname نیلا\n",
            "Lastname امین\n",
            "degree: PHD\n",
            "-------------------------------------\n",
            "Form: 5\n",
            "ID 9527502\n",
            "Firstname امیوعلی\n",
            "Lastname حسینزاده\n",
            "degree: BS\n",
            "-------------------------------------\n",
            "Form: 6\n",
            "ID 9323993\n",
            "Firstname طاها\n",
            "Lastname سماواتی\n",
            "degree: BS\n",
            "-------------------------------------\n",
            "Form: 7\n",
            "ID 98731243\n",
            "Firstname فرزاد\n",
            "Lastname صبحی\n",
            "degree: MS\n",
            "-------------------------------------\n",
            "Form: 8\n",
            "ID 95012121\n",
            "Firstname رزیتا\n",
            "Lastname عظیمیان\n",
            "degree: MS\n",
            "-------------------------------------\n",
            "Form: 9\n",
            "ID 99337567\n",
            "Firstname سهبد\n",
            "Lastname تابعی\n",
            "degree: BS\n",
            "-------------------------------------\n",
            "Form: 10\n",
            "ID 9312567\n",
            "Firstname سیما\n",
            "Lastname نظری\n",
            "degree: BS\n",
            "-------------------------------------\n",
            "Form: 11\n",
            "ID 98444114\n",
            "Firstname فزناز\n",
            "Lastname عسننژطد\n",
            "degree: BS\n",
            "-------------------------------------\n",
            "Form: 12\n",
            "ID 11342135\n",
            "Firstname زهراه\n",
            "Lastname بیگی\n",
            "degree: MS\n",
            "-------------------------------------\n",
            "Form: 13\n",
            "ID 92345667\n",
            "Firstname پیتا\n",
            "Lastname بابایی\n",
            "degree: MS\n",
            "-------------------------------------\n",
            "Form: 14\n",
            "ID 9386137\n",
            "Firstname ستایش\n",
            "Lastname ثرهادی\n",
            "degree: PHD\n",
            "-------------------------------------\n",
            "Form: 15\n",
            "ID 9152832\n",
            "Firstname علی\n",
            "Lastname بیراوند\n",
            "degree: MS\n",
            "-------------------------------------\n",
            "Form: 16\n",
            "ID 8252190\n",
            "Firstname اصغر\n",
            "Lastname مثدم\n",
            "degree: PHD\n",
            "-------------------------------------\n",
            "Form: 17\n",
            "ID 9513367\n",
            "Firstname شاهین\n",
            "Lastname کامبیزی\n",
            "degree: PHD\n",
            "-------------------------------------\n",
            "Form: 18\n",
            "ID 93774415\n",
            "Firstname برویذ\n",
            "Lastname اجمدیان\n",
            "degree: MS\n",
            "-------------------------------------\n",
            "Form: 19\n",
            "ID 9731203\n",
            "Firstname سووقا\n",
            "Lastname انصاوی\n",
            "degree: BS\n",
            "-------------------------------------\n",
            "Form: 20\n",
            "ID 96624751\n",
            "Firstname زینب\n",
            "Lastname صتاوی\n",
            "degree: BS\n",
            "Time:  14.221325682003226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}